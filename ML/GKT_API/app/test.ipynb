{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class PredictIn(BaseModel):\n",
    "    features: List[int]  # feature 벡터\n",
    "    questions: List[int]  # 질문 ID 리스트\n",
    "    next_skills: List[int]  # 다음 문제의 스킬 리스트\n",
    "    next_answers: List[int]  # 다음 문제의 실제 정답 리스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './models.py')\n",
    "sys.path.insert(1, './layers.py')\n",
    "sys.path.insert(2, './utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "import torch\n",
    "\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6532\\1436957623.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('model.pth')\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.20 GiB is allocated by PyTorch, and 20.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[0;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\serialization.py:1466\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1461\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1466\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1467\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1468\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1471\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\serialization.py:392\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m    391\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[1;32m--> 392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\storage.py:187\u001b[0m, in \u001b[0;36m_StorageBase.to\u001b[1;34m(self, device, non_blocking)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, device: torch\u001b[38;5;241m.\u001b[39mdevice, non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:  \u001b[38;5;66;03m# type: ignore[type-var, misc] # noqa: E704\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gkt-api\\lib\\site-packages\\torch\\_utils.py:89\u001b[0m, in \u001b[0;36m_to\u001b[1;34m(self, device, non_blocking)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse\n\u001b[0;32m     88\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 89\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.20 GiB is allocated by PyTorch, and 20.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AKIAU6GDX5YR36D2CSVP'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getenv('AWS_ACCESS_KEY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GKT(\n",
       "  (emb_x): Embedding(49140, 32)\n",
       "  (emb_c): Embedding(4096, 32, padding_idx=4095)\n",
       "  (f_self): MLP(\n",
       "    (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (f_neighbor_list): ModuleList(\n",
       "    (0-1): 2 x MLP(\n",
       "      (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (erase_add_gate): EraseAddGate(\n",
       "    (erase): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (add): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (gru): GRUCell(32, 32)\n",
       "  (predict): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>QuizCode</th>\n",
       "      <th>Correct</th>\n",
       "      <th>CreDate</th>\n",
       "      <th>f_mchapter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a93858f1-ee72-4961-bc81-99cc56381106</td>\n",
       "      <td>30140114</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-01-01 00:04:00</td>\n",
       "      <td>14201779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a93858f1-ee72-4961-bc81-99cc56381106</td>\n",
       "      <td>30140113</td>\n",
       "      <td>O</td>\n",
       "      <td>2024-01-01 00:04:00</td>\n",
       "      <td>14201779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a93858f1-ee72-4961-bc81-99cc56381106</td>\n",
       "      <td>30140115</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-01-01 00:04:00</td>\n",
       "      <td>14201779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a93858f1-ee72-4961-bc81-99cc56381106</td>\n",
       "      <td>30140110</td>\n",
       "      <td>O</td>\n",
       "      <td>2024-01-01 00:04:00</td>\n",
       "      <td>14201779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a93858f1-ee72-4961-bc81-99cc56381106</td>\n",
       "      <td>30140044</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-01-01 00:04:00</td>\n",
       "      <td>14201779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885717</th>\n",
       "      <td>d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6</td>\n",
       "      <td>30159257</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-09-30 23:58:00.000</td>\n",
       "      <td>14201893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885718</th>\n",
       "      <td>d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6</td>\n",
       "      <td>30159256</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-09-30 23:58:00.000</td>\n",
       "      <td>14201893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885719</th>\n",
       "      <td>d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6</td>\n",
       "      <td>30159255</td>\n",
       "      <td>O</td>\n",
       "      <td>2024-09-30 23:58:00.000</td>\n",
       "      <td>14201893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885720</th>\n",
       "      <td>d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6</td>\n",
       "      <td>30159254</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-09-30 23:58:00.000</td>\n",
       "      <td>14201893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885721</th>\n",
       "      <td>d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6</td>\n",
       "      <td>30159253</td>\n",
       "      <td>O</td>\n",
       "      <td>2024-09-30 23:58:00.000</td>\n",
       "      <td>14201893.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12885722 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        UserID  QuizCode Correct  \\\n",
       "0         a93858f1-ee72-4961-bc81-99cc56381106  30140114       X   \n",
       "1         a93858f1-ee72-4961-bc81-99cc56381106  30140113       O   \n",
       "2         a93858f1-ee72-4961-bc81-99cc56381106  30140115       X   \n",
       "3         a93858f1-ee72-4961-bc81-99cc56381106  30140110       O   \n",
       "4         a93858f1-ee72-4961-bc81-99cc56381106  30140044       X   \n",
       "...                                        ...       ...     ...   \n",
       "12885717  d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6  30159257       X   \n",
       "12885718  d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6  30159256       X   \n",
       "12885719  d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6  30159255       O   \n",
       "12885720  d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6  30159254       X   \n",
       "12885721  d7a24bd1-a1c5-4e36-a8de-e36a2ebafea6  30159253       O   \n",
       "\n",
       "                          CreDate  f_mchapter_id  \n",
       "0             2024-01-01 00:04:00     14201779.0  \n",
       "1             2024-01-01 00:04:00     14201779.0  \n",
       "2             2024-01-01 00:04:00     14201779.0  \n",
       "3             2024-01-01 00:04:00     14201779.0  \n",
       "4             2024-01-01 00:04:00     14201779.0  \n",
       "...                           ...            ...  \n",
       "12885717  2024-09-30 23:58:00.000     14201893.0  \n",
       "12885718  2024-09-30 23:58:00.000     14201893.0  \n",
       "12885719  2024-09-30 23:58:00.000     14201893.0  \n",
       "12885720  2024-09-30 23:58:00.000     14201893.0  \n",
       "12885721  2024-09-30 23:58:00.000     14201893.0  \n",
       "\n",
       "[12885722 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv('.env')\n",
    "\n",
    "# 환경 변수를 사용하여 Boto3 S3 클라이언트 초기화\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "    region_name=os.getenv('AWS_DEFAULT_REGION')\n",
    ")\n",
    "\n",
    "# S3 버킷과 파일 이름 설정\n",
    "bucket_name = 'big9-project-01'\n",
    "file_name = 'data/tbl_app_testhisdtl/filtered_combined_user_data.csv'\n",
    "\n",
    "# S3에서 파일 내용 가져오기\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "file_content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "# 문자열 데이터를 데이터프레임으로 변환\n",
    "data_frame = pd.read_csv(StringIO(file_content))\n",
    "\n",
    "# 데이터프레임 출력\n",
    "data_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID\n",
       "75827c22-6895-4c9d-83e4-9b7cb21116e9    1867\n",
       "82e9fc77-17ce-44f9-893b-e0442b742ab3    1750\n",
       "1d4850ac-1977-4309-a6e8-9535b743f407    1549\n",
       "fa7ab926-db6e-4e9b-accc-b56f341db193    1540\n",
       "a3f780b0-d1ef-47ab-848c-c7f72949589c    1506\n",
       "                                        ... \n",
       "785a9277-34d4-46c5-b0ea-f0794a3ac8cf       1\n",
       "9d312f4d-fc93-413e-89b8-f4afb45521c8       1\n",
       "66537af1-db89-4ff1-ad61-a5ac843a6ce5       1\n",
       "b96da590-96d7-4aea-abc4-f0725e622138       1\n",
       "9b150cd7-5351-47c3-94d0-8efce8b4b5ee       1\n",
       "Name: count, Length: 56565, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['UserID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        UserID  QuizCode  Correct  \\\n",
      "12810841  75827c22-6895-4c9d-83e4-9b7cb21116e9  30159314        1   \n",
      "12810842  75827c22-6895-4c9d-83e4-9b7cb21116e9  30159313        1   \n",
      "12810854  75827c22-6895-4c9d-83e4-9b7cb21116e9  30159315        0   \n",
      "12810875  75827c22-6895-4c9d-83e4-9b7cb21116e9  30159317        1   \n",
      "12810876  75827c22-6895-4c9d-83e4-9b7cb21116e9  30159316        0   \n",
      "12812795  75827c22-6895-4c9d-83e4-9b7cb21116e9  30161232        1   \n",
      "12812796  75827c22-6895-4c9d-83e4-9b7cb21116e9  30161231        1   \n",
      "12812805  75827c22-6895-4c9d-83e4-9b7cb21116e9  30161233        1   \n",
      "12812808  75827c22-6895-4c9d-83e4-9b7cb21116e9  30161235        1   \n",
      "12812809  75827c22-6895-4c9d-83e4-9b7cb21116e9  30161234        1   \n",
      "\n",
      "                          CreDate  f_mchapter_id  skill  skill_with_answer  \n",
      "12810841  2024-09-29 16:52:00.000     14201897.0     63                127  \n",
      "12810842  2024-09-29 16:52:00.000     14201897.0     63                127  \n",
      "12810854  2024-09-29 16:52:00.000     14201897.0     63                126  \n",
      "12810875  2024-09-29 16:52:00.000     14201897.0     63                127  \n",
      "12810876  2024-09-29 16:52:00.000     14201897.0     63                126  \n",
      "12812795  2024-09-29 18:16:00.000     14201869.0     54                109  \n",
      "12812796  2024-09-29 18:16:00.000     14201868.0     53                107  \n",
      "12812805  2024-09-29 18:16:00.000     14201869.0     54                109  \n",
      "12812808  2024-09-29 18:16:00.000     14201868.0     53                107  \n",
      "12812809  2024-09-29 18:16:00.000     14201868.0     53                107  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6532\\2691010169.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data.sort_values(by=[\"UserID\", \"CreDate\"], inplace=True)  # \"CreDate\" 컬럼을 기준으로 정렬\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6532\\2691010169.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['skill'], _ = pd.factorize(user_data['f_mchapter_id'], sort=True)  # we can also use problem_id to represent exercises\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6532\\2691010169.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Correct'] = user_data['Correct'].map({'O': 1, 'X': 0})\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6532\\2691010169.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['skill_with_answer'] = user_data['skill'] * 2 + user_data['Correct']\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임에서 유저 데이터 로드\n",
    "df = data_frame\n",
    "user_id = '75827c22-6895-4c9d-83e4-9b7cb21116e9'\n",
    "user_data = df[df['UserID'] == user_id]\n",
    "\n",
    "# Step 0 - 정렬: 가장 오래된 기록부터 정렬\n",
    "user_data.sort_values(by=[\"UserID\", \"CreDate\"], inplace=True)  # \"CreDate\" 컬럼을 기준으로 정렬\n",
    "\n",
    "# Step 2 - Enumerate skill id\n",
    "user_data['skill'], _ = pd.factorize(user_data['f_mchapter_id'], sort=True)  # we can also use problem_id to represent exercises\n",
    "\n",
    "# correct 생성 (O -> 1, X -> 0)\n",
    "user_data['Correct'] = user_data['Correct'].map({'O': 1, 'X': 0})\n",
    "\n",
    "# Step 3 - Cross skill id with answer to form a synthetic feature\n",
    "# use_binary: (0,1); !use_binary: (1,2,3,4,5,6,7,8,9,10,11,12). Either way, the correct result index is guaranteed to be 1\n",
    "user_data['skill_with_answer'] = user_data['skill'] * 2 + user_data['Correct']\n",
    "\n",
    "print(user_data.tail(10))\n",
    "\n",
    "\n",
    "# 유저 풀이 시퀀스 및 다음 문제 정의\n",
    "features = user_data['skill_with_answer'].tolist()\n",
    "questions = user_data['skill'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_skills = [1,2,3,4,5,6,7,8,9,10]\n",
    "next_answers = [1,1,0,1,0,1,0,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,10):\n",
    "    features.append(next_skills[i])\n",
    "    questions.append(next_skills[i] * 2 + next_answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 텐서로 변환 및 디바이스 이동\n",
    "features_tensor = torch.tensor(features, dtype=torch.long).unsqueeze(0).to('cuda')\n",
    "questions_tensor = torch.tensor(questions, dtype=torch.long).unsqueeze(0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_res, _, _, _ = model(features_tensor, questions_tensor)  # 입력값과 동일한 디바이스에서 수행\n",
    "    next_preds = pred_res.squeeze(0)[-len(next_skills):]  # 다음 문제에 해당하는 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9288, 0.6930, 0.7580, 0.8897, 0.9402, 0.9214, 0.8919, 0.8065, 0.9023,\n",
       "        0.9246], device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음에 풀 10문제의 예측값 및 정오표:\n",
      "문제 1: 정답 확률 = 0.9288 (1) 실제 = 1 -> 분석: 개념 확립 (정답 확신)\n",
      "문제 2: 정답 확률 = 0.6930 (0) 실제 = 1 -> 분석: 찍음 (운 좋게 맞춤)\n",
      "문제 3: 정답 확률 = 0.7580 (0) 실제 = 0 -> 분석: 개념 확립 (오답 확신)\n",
      "문제 4: 정답 확률 = 0.8897 (1) 실제 = 1 -> 분석: 개념 확립 (정답 확신)\n",
      "문제 5: 정답 확률 = 0.9402 (1) 실제 = 0 -> 분석: 실수 (과신)\n",
      "문제 6: 정답 확률 = 0.9214 (1) 실제 = 1 -> 분석: 개념 확립 (정답 확신)\n",
      "문제 7: 정답 확률 = 0.8919 (1) 실제 = 0 -> 분석: 실수 (과신)\n",
      "문제 8: 정답 확률 = 0.8065 (0) 실제 = 1 -> 분석: 찍음 (운 좋게 맞춤)\n",
      "문제 9: 정답 확률 = 0.9023 (1) 실제 = 1 -> 분석: 개념 확립 (정답 확신)\n",
      "문제 10: 정답 확률 = 0.9246 (1) 실제 = 1 -> 분석: 개념 확립 (정답 확신)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.85\n",
    "\n",
    "print(\"다음에 풀 10문제의 예측값 및 정오표:\")\n",
    "for i, pred in enumerate(next_preds.tolist()):\n",
    "    # 예측된 결과 결정\n",
    "    pred_result = 1 if pred >= threshold else 0\n",
    "    # 실제 결과와 예측 결과 비교\n",
    "    if pred_result == next_answers[i]:\n",
    "        if pred_result == 1:\n",
    "            analysis = \"개념 확립 (정답 확신)\"\n",
    "        else:\n",
    "            analysis = \"개념 확립 (오답 확신)\"\n",
    "    else:\n",
    "        if pred_result == 1:\n",
    "            analysis = \"실수 (과신)\"\n",
    "        else:\n",
    "            analysis = \"찍음 (운 좋게 맞춤)\"\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"문제 {next_skills[i]}: 정답 확률 = {pred:.4f} ({pred_result}) 실제 = {next_answers[i]} -> 분석: {analysis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gkt-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
