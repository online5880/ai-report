{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232806 entries, 0 to 232805\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   userid         232806 non-null  object \n",
      " 1   mcode          232806 non-null  object \n",
      " 2   l_title        232806 non-null  object \n",
      " 3   leccode        232806 non-null  object \n",
      " 4   f_lchapter_id  232806 non-null  float64\n",
      " 5   f_mchapter_id  232806 non-null  object \n",
      " 6   l_type_nm      232806 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 12.4+ MB\n",
      "None\n",
      "id_map.json 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. 첫 번째 파일(tbl_app_testhisdtl_202401.parquet) 불러오기\n",
    "file_path = 'tbl_app_testhisdtl/tbl_app_testhisdtl_202401.parquet'  \n",
    "df_tbl_app_testhisdtl = pd.read_parquet(file_path)\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "df_tbl_app_testhisdtl.drop(columns=['No', 'Answer', 'Correct', 'CreDate', 'LM_IDX'], inplace=True)\n",
    "\n",
    "# 2. 두 번째 파일(e_content_meta.csv) 불러오기\n",
    "e_content_meta_file_path = 'e_content_meta.csv'\n",
    "df_e_content_meta = pd.read_csv(e_content_meta_file_path)\n",
    "\n",
    "# 데이터 필터링\n",
    "df_2022 = df_e_content_meta[(df_e_content_meta['leccourse_nm'] == '2022 개정') & \n",
    "                            (df_e_content_meta['l_type_nm'] != '탭)한입 쏙 학교 공부 > 한입 문제')]\n",
    "\n",
    "# 'l_type_nm'이 '기)교과서 진도학습'이고, 'l_title'이 '단원 마무리 문제'인 행을 제외\n",
    "df_2022_filtered = df_2022[~((df_2022['l_type_nm'] == '기)교과서 진도학습') & \n",
    "                             (df_2022['l_title'] == '단원 마무리 문제'))]\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "e_content_meta = df_2022_filtered.drop(columns=['unique_content_nm', 'l_type', 'service_1depth', \n",
    "                                                'service_2depth', 'subject', 'subject_nm', 'content_grade', \n",
    "                                                'content_grade_nm', 'term', 'term_nm', 'leccourse', 'leccourse_nm', \n",
    "                                                'l_level', 'l_info', 'l_template', 'l_template_nm', 'u_idx', 'u_parent_idx',\n",
    "                                                'u_seq', 'u_type', 'u_lchapter', 'u_mchapter', 'textbooktype', 'u_title', \n",
    "                                                'l_idx', 'l_seq'])\n",
    "\n",
    "\n",
    "# 3. 세 번째 파일(t_problem_analysis.csv) 불러오기\n",
    "t_problem_analysis_file_path = 't_problem_analysis.csv'\n",
    "df_t_problem_analysis = pd.read_csv(t_problem_analysis_file_path)\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "t_problem_analysis = df_t_problem_analysis.drop(columns=['f_file_id', 'f_emh_cd', 'f_eduprocess_cd', \n",
    "                                                         'f_area_cd', 'f_area_cd', 'f_chapkind_cd', \n",
    "                                                         'f_schapter_id', 'f_tchapter_id', 'f_echapter_id', \n",
    "                                                         'f_difficult_cd', 'f_analysis_id', 'f_studytree_id', \n",
    "                                                         'f_test_cnt', 'f_good_cnt', 'f_deleteyn', 'f_mginfo', \n",
    "                                                         'f_subject_id'])\n",
    "\n",
    "# 4. 데이터 병합\n",
    "# 'mCode'와 'quizcode' 컬럼 이름 일치시키기\n",
    "if 'mCode' in df_tbl_app_testhisdtl.columns:\n",
    "    df_tbl_app_testhisdtl.rename(columns={'mCode': 'mcode'}, inplace=True)\n",
    "\n",
    "if 'f_problem_id' in t_problem_analysis.columns:\n",
    "    t_problem_analysis.rename(columns={'f_problem_id': 'quizcode'}, inplace=True)\n",
    "\n",
    "if 'QuizCode' in df_tbl_app_testhisdtl.columns:\n",
    "    df_tbl_app_testhisdtl.rename(columns={'QuizCode': 'quizcode'}, inplace=True)\n",
    "\n",
    "# 'UserID'가 존재하면 'userid'로 컬럼명 변경\n",
    "if 'UserID' in df_tbl_app_testhisdtl.columns:\n",
    "    df_tbl_app_testhisdtl.rename(columns={'UserID': 'userid'}, inplace=True)\n",
    "\n",
    "# 병합 전에 f_lchapter_id와 f_mchapter_id를 문자열로 변환\n",
    "# 소수점을 제거하고 정수형으로 변환 후 문자열로 처리\n",
    "t_problem_analysis['f_mchapter_id'] = t_problem_analysis['f_mchapter_id'].dropna().astype(int).astype(str)\n",
    "\n",
    "# mcode를 기준으로 병합\n",
    "merged_df = pd.merge(df_tbl_app_testhisdtl, e_content_meta, on='mcode', how='inner')\n",
    "\n",
    "# 중복 행 제거\n",
    "df_unique = merged_df.drop_duplicates()\n",
    "\n",
    "# quizcode로 병합\n",
    "merged_df1 = pd.merge(df_unique, t_problem_analysis, on='quizcode', how='inner')\n",
    "\n",
    "# 최종 중복 제거\n",
    "df_unique1 = merged_df1.drop_duplicates()\n",
    "\n",
    "# 5. 널값 처리: 'f_mchapter_id', 'f_lchapter_id', 'userid' 컬럼의 널값 제거\n",
    "df_unique1 = df_unique1.dropna(subset=['f_mchapter_id', 'f_lchapter_id', 'userid'])\n",
    "df_unique1 = df_unique1.drop_duplicates(subset=['userid', 'f_lchapter_id', 'f_mchapter_id'])\n",
    "# 6. 최종 데이터프레임에서 필요한 컬럼만 선택\n",
    "df_final = df_unique1[['userid', 'mcode', 'l_title', 'leccode', 'f_lchapter_id', 'f_mchapter_id','l_type_nm']]\n",
    "df_final = df_final.drop_duplicates(subset=['userid', 'mcode', 'f_mchapter_id'])\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "# 7. 데이터프레임 정보 확인\n",
    "print(df_final.info())  # 최종 데이터프레임 확인\n",
    "\n",
    "# 8. 데이터프레임에서 'mcode', 'f_mchapter_id', 'userid' 컬럼 값 가져오기\n",
    "mcodes = df_final['mcode'].unique()\n",
    "f_mchapter_ids = df_final['f_mchapter_id'].unique()\n",
    "user_ids = df_final['userid'].unique()\n",
    "\n",
    "# 9. 타입별 독립적 ID 넘버링\n",
    "# 학생 ID 넘버링\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "\n",
    "# 중단원 ID 넘버링\n",
    "f_mchapter_id_map = {f_mchapter_id: idx for idx, f_mchapter_id in enumerate(f_mchapter_ids)}\n",
    "\n",
    "# 강의 ID 넘버링\n",
    "mcode_map = {mcode: idx for idx, mcode in enumerate(mcodes)}\n",
    "\n",
    "# 10. 타입별로 id_map 생성\n",
    "id_map = {\n",
    "    \"students\": user_id_map,\n",
    "    \"concepts\": f_mchapter_id_map,\n",
    "    \"lectures\": mcode_map\n",
    "}\n",
    "\n",
    "# id_map.json 저장\n",
    "with open('id_map.json', 'w') as json_file:\n",
    "    json.dump(id_map, json_file, indent=4)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"id_map.json 파일이 생성되었습니다.\")\n",
    "df_final.to_csv(\"df_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232806 entries, 0 to 232805\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   userid         232806 non-null  object \n",
      " 1   mcode          232806 non-null  object \n",
      " 2   l_title        232806 non-null  object \n",
      " 3   leccode        232806 non-null  object \n",
      " 4   f_lchapter_id  232806 non-null  float64\n",
      " 5   f_mchapter_id  232806 non-null  object \n",
      " 6   l_type_nm      232806 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 12.4+ MB\n",
      "None\n",
      "id_map.json 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. 첫 번째 파일(tbl_app_testhisdtl_202401.parquet) 불러오기\n",
    "file_path = 'tbl_app_testhisdtl/tbl_app_testhisdtl_202401.parquet'  \n",
    "df_tbl_app_testhisdtl = pd.read_parquet(file_path)\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "df_tbl_app_testhisdtl.drop(columns=['No', 'Answer', 'Correct', 'CreDate', 'LM_IDX'], inplace=True)\n",
    "\n",
    "# 2. 두 번째 파일(e_content_meta.csv) 불러오기\n",
    "e_content_meta_file_path = 'e_content_meta.csv'\n",
    "df_e_content_meta = pd.read_csv(e_content_meta_file_path)\n",
    "\n",
    "# 데이터 필터링\n",
    "df_2022 = df_e_content_meta[(df_e_content_meta['leccourse_nm'] == '2022 개정') & \n",
    "                            (df_e_content_meta['l_type_nm'] != '탭)한입 쏙 학교 공부 > 한입 문제')]\n",
    "\n",
    "# 'l_type_nm'이 '기)교과서 진도학습'이고, 'l_title'이 '단원 마무리 문제'인 행을 제외\n",
    "df_2022_filtered = df_2022[~((df_2022['l_type_nm'] == '기)교과서 진도학습') & \n",
    "                             (df_2022['l_title'] == '단원 마무리 문제'))]\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "e_content_meta = df_2022_filtered.drop(columns=['unique_content_nm', 'l_type', 'service_1depth', \n",
    "                                                'service_2depth', 'subject', 'subject_nm', 'content_grade', \n",
    "                                                'content_grade_nm', 'term', 'term_nm', 'leccourse', 'leccourse_nm', \n",
    "                                                'l_level', 'l_info', 'l_template', 'l_template_nm', 'u_idx', 'u_parent_idx',\n",
    "                                                'u_seq', 'u_type', 'u_lchapter', 'u_mchapter', 'textbooktype', 'u_title', \n",
    "                                                'l_idx', 'l_seq'])\n",
    "\n",
    "\n",
    "# 3. 세 번째 파일(t_problem_analysis.csv) 불러오기\n",
    "t_problem_analysis_file_path = 't_problem_analysis.csv'\n",
    "df_t_problem_analysis = pd.read_csv(t_problem_analysis_file_path)\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "t_problem_analysis = df_t_problem_analysis.drop(columns=['f_file_id', 'f_emh_cd', 'f_eduprocess_cd', \n",
    "                                                         'f_area_cd', 'f_area_cd', 'f_chapkind_cd', \n",
    "                                                         'f_schapter_id', 'f_tchapter_id', 'f_echapter_id', \n",
    "                                                         'f_difficult_cd', 'f_analysis_id', 'f_studytree_id', \n",
    "                                                         'f_test_cnt', 'f_good_cnt', 'f_deleteyn', 'f_mginfo', \n",
    "                                                         'f_subject_id'])\n",
    "\n",
    "# 4. 데이터 병합\n",
    "# 'mCode'와 'quizcode' 컬럼 이름 일치시키기\n",
    "if 'mCode' in df_tbl_app_testhisdtl.columns:\n",
    "    df_tbl_app_testhisdtl.rename(columns={'mCode': 'mcode'}, inplace=True)\n",
    "\n",
    "if 'f_problem_id' in t_problem_analysis.columns:\n",
    "    t_problem_analysis.rename(columns={'f_problem_id': 'quizcode'}, inplace=True)\n",
    "\n",
    "if 'QuizCode' in df_tbl_app_testhisdtl.columns:\n",
    "    df_tbl_app_testhisdtl.rename(columns={'QuizCode': 'quizcode'}, inplace=True)\n",
    "\n",
    "# 'UserID'가 존재하면 'userid'로 컬럼명 변경\n",
    "if 'UserID' in df_tbl_app_testhisdtl.columns:\n",
    "    df_tbl_app_testhisdtl.rename(columns={'UserID': 'userid'}, inplace=True)\n",
    "\n",
    "# 병합 전에 f_lchapter_id와 f_mchapter_id를 문자열로 변환\n",
    "# 소수점을 제거하고 정수형으로 변환 후 문자열로 처리\n",
    "t_problem_analysis['f_mchapter_id'] = t_problem_analysis['f_mchapter_id'].dropna().astype(int).astype(str)\n",
    "\n",
    "# mcode를 기준으로 병합\n",
    "merged_df = pd.merge(df_tbl_app_testhisdtl, e_content_meta, on='mcode', how='inner')\n",
    "\n",
    "# 중복 행 제거\n",
    "df_unique = merged_df.drop_duplicates()\n",
    "\n",
    "# quizcode로 병합\n",
    "merged_df1 = pd.merge(df_unique, t_problem_analysis, on='quizcode', how='inner')\n",
    "\n",
    "# 최종 중복 제거\n",
    "df_unique1 = merged_df1.drop_duplicates()\n",
    "\n",
    "# 5. 널값 처리: 'f_mchapter_id', 'f_lchapter_id', 'userid' 컬럼의 널값 제거\n",
    "df_unique1 = df_unique1.dropna(subset=['f_mchapter_id', 'f_lchapter_id', 'userid'])\n",
    "df_unique1 = df_unique1.drop_duplicates(subset=['userid', 'f_lchapter_id', 'f_mchapter_id'])\n",
    "# 6. 최종 데이터프레임에서 필요한 컬럼만 선택\n",
    "df_final = df_unique1[['userid', 'mcode', 'l_title', 'leccode', 'f_lchapter_id', 'f_mchapter_id','l_type_nm']]\n",
    "df_final = df_final.drop_duplicates(subset=['userid', 'mcode', 'f_mchapter_id'])\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "# 7. 데이터프레임 정보 확인\n",
    "print(df_final.info())  # 최종 데이터프레임 확인\n",
    "\n",
    "# 8. 데이터프레임에서 'mcode', 'f_mchapter_id', 'userid' 컬럼 값 가져오기\n",
    "mcodes = df_final['mcode'].unique()\n",
    "f_mchapter_ids = df_final['f_mchapter_id'].unique()\n",
    "user_ids = df_final['userid'].unique()\n",
    "\n",
    "# 9. 넘버링: 각 고유한 값들에 대해 인덱스를 매기기\n",
    "# userid 넘버링은 0번부터 시작\n",
    "start_user = 0\n",
    "\n",
    "# userid 넘버링 (0번부터 시작)\n",
    "user_id_map = {user_id: idx + start_user for idx, user_id in enumerate(user_ids)}\n",
    "\n",
    "# f_mchapter_id 넘버링 (userid 끝번호 이후부터 시작)\n",
    "start_fmchapter = start_user + len(user_ids)\n",
    "f_mchapter_id_map = {f_mchapter_id: idx + start_fmchapter for idx, f_mchapter_id in enumerate(f_mchapter_ids)}\n",
    "\n",
    "# mcode 넘버링 (f_mchapter_id 끝번호 이후부터 시작)\n",
    "start_mcode = start_fmchapter + len(f_mchapter_ids)\n",
    "mcode_map = {mcode: idx + start_mcode for idx, mcode in enumerate(mcodes)}\n",
    "\n",
    "# 10. 최종 id_map 생성\n",
    "id_map = {}\n",
    "id_map.update(user_id_map)\n",
    "id_map.update(f_mchapter_id_map)\n",
    "id_map.update(mcode_map)\n",
    "\n",
    "# id_map의 모든 값을 정수로 유지\n",
    "id_map = {key: int(value) for key, value in id_map.items()}\n",
    "\n",
    "# 11. json 파일로 저장\n",
    "with open('id_map.json', 'w') as json_file:\n",
    "    json.dump(id_map, json_file, indent=4)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"id_map.json 파일이 생성되었습니다.\")\n",
    "df_final.to_csv(\"df_final.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_id.json 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프의 id 생성\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 데이터프레임에서 unique 값 추출\n",
    "user_ids = df_final['userid'].unique()\n",
    "f_mchapter_ids = df_final['f_mchapter_id'].unique()\n",
    "mcodes = df_final['mcode'].unique()  # f_lchapter_id 대신 mcode를 가져옴\n",
    "\n",
    "# 노드 정보 생성\n",
    "nodes = []\n",
    "\n",
    "# 'user' 타입 노드 추가\n",
    "for user_id in user_ids:\n",
    "    nodes.append({\"id\": user_id, \"type\": \"user\"})\n",
    "\n",
    "# 'mchapter' 타입 노드 추가\n",
    "for mchapter_id in f_mchapter_ids:\n",
    "    nodes.append({\"id\": mchapter_id, \"type\": \"mchapter\"})\n",
    "\n",
    "# 'mcode' 타입 노드 추가 (f_lchapter_id 대신 mcode를 사용)\n",
    "for mcode in mcodes:\n",
    "    nodes.append({\"id\": mcode, \"type\": \"mcode\"})  # 'lchapter' 대신 'mcode' 타입으로 추가\n",
    "\n",
    "# JSON 구조 생성\n",
    "node_data = {\"nodes\": nodes}\n",
    "\n",
    "# JSON 파일로 저장\n",
    "with open(\"node_id.json\", \"w\") as json_file:\n",
    "    json.dump(node_data, json_file, indent=4)\n",
    "\n",
    "print(\"node_id.json 파일이 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge.json 파일이 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# df_final이 준비된 상태여야 합니다.\n",
    "\n",
    "# 1. unique 값 추출\n",
    "unique_user_ids = df_final['userid'].unique()\n",
    "unique_f_mchapter_ids = df_final['f_mchapter_id'].unique()\n",
    "unique_mcode_ids = df_final['mcode'].unique()  # f_lchapter_id -> mcode로 변경\n",
    "\n",
    "# 2. \"userid -> f_mchapter_id\" 엣지 생성 (유니크한 값 기준)\n",
    "user_to_mchapter_edges = []\n",
    "\n",
    "for _, row in df_final.drop_duplicates(subset=['userid', 'f_mchapter_id']).iterrows():\n",
    "    weight = round(random.uniform(0, 1), 2)  # 랜덤 가중치 (0~1.0)\n",
    "    user_to_mchapter_edges.append({\n",
    "        \"source\": row[\"userid\"],\n",
    "        \"target\": row[\"f_mchapter_id\"],\n",
    "        \"weight\": weight\n",
    "    })\n",
    "\n",
    "# 3. \"f_mchapter_id -> mcode\" 엣지 생성 (유니크한 값 기준)\n",
    "mchapter_to_mcode_edges = []\n",
    "\n",
    "for _, row in df_final.drop_duplicates(subset=['f_mchapter_id', 'mcode']).iterrows():\n",
    "    mchapter_to_mcode_edges.append({\n",
    "        \"source\": row[\"f_mchapter_id\"],\n",
    "        \"target\": row[\"mcode\"],  # 'f_lchapter_id'를 'mcode'로 변경\n",
    "    })\n",
    "\n",
    "# 4. 모든 엣지 합치기\n",
    "all_edges = user_to_mchapter_edges + mchapter_to_mcode_edges\n",
    "\n",
    "# 5. JSON 구조 생성\n",
    "graph = {\"edges\": all_edges}  # \"links\" -> \"edges\"\n",
    "\n",
    "# 6. JSON 파일 저장\n",
    "with open('edge.json', 'w') as json_file:\n",
    "    json.dump(graph, json_file, indent=4)\n",
    "\n",
    "print(\"edge.json 파일이 성공적으로 생성되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge.json 파일이 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# df_final이 준비된 상태여야 합니다.\n",
    "\n",
    "# 1. unique 값 추출\n",
    "unique_user_ids = df_final['userid'].unique()\n",
    "unique_f_mchapter_ids = df_final['f_mchapter_id'].unique()\n",
    "unique_mcodes = df_final['mcode'].unique()\n",
    "\n",
    "# 2. \"userid -> f_mchapter_id\" 엣지 생성 (유니크한 값 기준)\n",
    "user_to_mchapter_edges = []  # links -> edges로 변경\n",
    "\n",
    "for _, row in df_final.drop_duplicates(subset=['userid', 'f_mchapter_id']).iterrows():\n",
    "    weight = round(random.uniform(0, 1), 2)  # 랜덤 가중치 (0~1.0)\n",
    "    user_to_mchapter_edges.append({\n",
    "        \"source\": row[\"userid\"],\n",
    "        \"target\": row[\"f_mchapter_id\"],\n",
    "        \"weight\": weight\n",
    "    })\n",
    "\n",
    "# 3. \"f_mchapter_id -> mcode\" 엣지 생성 (유니크한 값 기준)\n",
    "mchapter_to_mcode_edges = []  # links -> edges로 변경\n",
    "\n",
    "for _, row in df_final.drop_duplicates(subset=['f_mchapter_id', 'mcode']).iterrows():\n",
    "    mchapter_to_mcode_edges.append({\n",
    "        \"source\": row[\"f_mchapter_id\"],\n",
    "        \"target\": row[\"mcode\"]\n",
    "    })\n",
    "\n",
    "# 4. f_mchapter_id 값들끼리의 연결 추가\n",
    "f_mchapter_edges = []\n",
    "\n",
    "# f_mchapter_id 값들끼리의 모든 조합 생성\n",
    "for i, f_mchapter_id_1 in enumerate(unique_f_mchapter_ids):\n",
    "    for j, f_mchapter_id_2 in enumerate(unique_f_mchapter_ids):\n",
    "        if i != j:  # 동일한 값은 제외 (자기 자신과의 연결은 제외)\n",
    "            f_mchapter_edges.append({\n",
    "                \"source\": f_mchapter_id_1,\n",
    "                \"target\": f_mchapter_id_2\n",
    "            })\n",
    "\n",
    "# 5. 모든 엣지 합치기\n",
    "all_edges = user_to_mchapter_edges + mchapter_to_mcode_edges + f_mchapter_edges\n",
    "\n",
    "# 중복된 엣지 제거: 이 부분을 다시 점검하여 단순한 중복 제거 방식으로 처리\n",
    "seen_edges = set()\n",
    "unique_edges = []\n",
    "\n",
    "for edge in all_edges:\n",
    "    # 엣지의 source와 target을 튜플로 하여 set에 저장해 중복을 체크\n",
    "    edge_tuple = (edge[\"source\"], edge[\"target\"])\n",
    "    if edge_tuple not in seen_edges:\n",
    "        seen_edges.add(edge_tuple)\n",
    "        unique_edges.append(edge)\n",
    "\n",
    "# 6. JSON 구조 생성\n",
    "graph = {\"edges\": unique_edges}\n",
    "\n",
    "# 7. JSON 파일 저장\n",
    "with open('edge.json', 'w') as json_file:\n",
    "    json.dump(graph, json_file, indent=4)\n",
    "\n",
    "print(\"edge.json 파일이 성공적으로 생성되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G.json 파일이 성공적으로 생성되었습니다. 모든 중복이 제거되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# graph\n",
    "import json\n",
    "\n",
    "node_file_path = \"node_id.json\"\n",
    "link_file_path = \"edge.json\"\n",
    "\n",
    "with open(node_file_path, \"r\") as node_file:\n",
    "    node_data = json.load(node_file)\n",
    "\n",
    "with open(link_file_path, \"r\") as link_file:\n",
    "    link_data = json.load(link_file)\n",
    "\n",
    "# 'id' 기준으로 중복 제거\n",
    "unique_nodes = {node[\"id\"]: node for node in node_data[\"nodes\"]}.values()\n",
    "\n",
    "# 2. 중복 제거: 링크\n",
    "# ('source', 'target') 기준으로 중복 제거\n",
    "unique_edges = {(link[\"source\"], link[\"target\"]): link for link in link_data[\"edges\"]}.values()\n",
    "\n",
    "# 3. G.json 생성\n",
    "graph = {\n",
    "    # \"directed\": False,\n",
    "    # \"graph\": {},\n",
    "    \"nodes\": list(unique_nodes),  # 중복 제거된 노드 정보\n",
    "    \"edges\": list(unique_edges)   # 중복 제거된 링크 정보\n",
    "}\n",
    "\n",
    "# 4. G.json 파일 저장\n",
    "with open(\"G.json\", \"w\") as json_file:\n",
    "    json.dump(graph, json_file, indent=4)\n",
    "\n",
    "print(\"G.json 파일이 성공적으로 생성되었습니다. 모든 중복이 제거되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_to_mchapter_data.json와 mchapter_to_mcode_data.json 파일이 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df_final = pd.read_csv(\"df_final.csv\")\n",
    "\n",
    "# 1. \"userid -> f_mchapter_id\" 엣지 생성 (유니크한 값 기준)\n",
    "user_to_mchapter_data = []\n",
    "\n",
    "# `userid`와 `f_mchapter_id`를 이용하여 데이터 생성\n",
    "for _, row in df_final.drop_duplicates(subset=['userid', 'f_mchapter_id']).iterrows():\n",
    "    user_to_mchapter_data.append([row[\"userid\"], str(row[\"f_mchapter_id\"])])\n",
    "\n",
    "# 2. \"f_mchapter_id -> mcode\" 엣지 생성 (유니크한 값 기준)\n",
    "mchapter_to_mcode_data = []\n",
    "\n",
    "for _, row in df_final.drop_duplicates(subset=['f_mchapter_id', 'mcode']).iterrows():\n",
    "    mchapter_to_mcode_data.append([str(row[\"f_mchapter_id\"]), str(row[\"mcode\"])])\n",
    "\n",
    "# 3. 두 개의 JSON 파일로 저장\n",
    "\n",
    "# 2번 \"userid -> f_mchapter_id\" 엣지 데이터 JSON 저장\n",
    "user_to_mchapter_json = 'user_to_mchapter_data.json'\n",
    "with open(user_to_mchapter_json, mode='w') as file:\n",
    "    json.dump(user_to_mchapter_data, file, indent=4)\n",
    "\n",
    "# 3번 \"f_mchapter_id -> mcode\" 엣지 데이터 JSON 저장\n",
    "mchapter_to_mcode_json = 'mchapter_to_mcode_data.json'\n",
    "with open(mchapter_to_mcode_json, mode='w') as file:\n",
    "    json.dump(mchapter_to_mcode_data, file, indent=4)\n",
    "\n",
    "print(f\"{user_to_mchapter_json}와 {mchapter_to_mcode_json} 파일이 성공적으로 생성되었습니다.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
