{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 핵심키워드_v2 기존 데이터와 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 성취기준 데이터 로드\n",
    "achievement_data = pd.read_excel('merged_final_data.xlsx')  # 성취기준 데이터 파일\n",
    "keywords_data = pd.read_excel('성취기준.xlsx')  # 핵심키워드_v2 파일\n",
    "\n",
    "# 성취기준코드를 기준으로 병합\n",
    "merged_data = pd.merge(achievement_data, keywords_data, on='성취기준코드', how='left')\n",
    "\n",
    "\n",
    "# 결과 저장\n",
    "merged_data.to_excel('merged_final_data_new.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엑셀파일 => csv 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 파일이 'merged_final_data_new - 복사본.csv'로 성공적으로 변환되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 경로\n",
    "excel_file = 'merged_final_data_new - 복사본.xlsx'  # 엑셀 파일 이름 또는 경로\n",
    "csv_file = 'merged_final_data_new - 복사본.csv'  # 변환할 CSV 파일 이름\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"엑셀 파일이 '{csv_file}'로 성공적으로 변환되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML 파일이 'new_knowledge_graph_v2.html'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 데이터 로드\n",
    "file_name = \"merged_final_data_new - 복사본.csv\"  \n",
    "data = pd.read_csv(file_name)\n",
    "\n",
    "# 필수 컬럼 확인\n",
    "required_columns = [\n",
    "    \"f_mchapter_nm\", \"f_mchapter_id\", \"성취기준 내용\", \"성취기준코드\", \"핵심키워드_v2\",\n",
    "    \"성취수준 A\", \"성취수준 B\", \"성취수준 C\", \"f_schapter_id\", \"f_schapter_nm\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"필수 컬럼 '{col}'이(가) 데이터에 없습니다.\")\n",
    "\n",
    "# 중복된 텍스트 제거\n",
    "data = data.drop_duplicates(subset=[\"f_mchapter_nm\", \"성취기준 내용\", \"핵심키워드_v2\"])\n",
    "\n",
    "# 2. 데이터 결합 및 전처리\n",
    "# 텍스트 정제\n",
    "data[\"combined_text\"] = (\n",
    "    data[\"f_mchapter_nm\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"성취기준 내용\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"핵심키워드_v2\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True)\n",
    ")\n",
    "data[\"tooltip\"] = (\n",
    "    \"소단원명: \" + data[\"f_schapter_nm\"].fillna(\"\") +\n",
    "    \"<br>성취수준 A: \" + data[\"성취수준 A\"].fillna(\"\") +\n",
    "    \"<br>성취수준 B: \" + data[\"성취수준 B\"].fillna(\"\") +\n",
    "    \"<br>성취수준 C: \" + data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# 3. 유사도 계산\n",
    "# Sentence-BERT 유사도\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"combined_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF 유사도\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"combined_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 최종 유사도\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 4. 그래프 생성\n",
    "threshold = 0.8\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "for _, row in data.iterrows():\n",
    "    level_color = \"red\" if pd.notna(row[\"성취수준 A\"]) else \"orange\" if pd.notna(row[\"성취수준 B\"]) else \"yellow\"\n",
    "    graph.add_node(\n",
    "        str(row[\"f_mchapter_id\"]),\n",
    "        label=row[\"f_mchapter_nm\"],\n",
    "        tooltip=row[\"tooltip\"],\n",
    "        color=level_color,\n",
    "        size=20 if pd.notna(row[\"성취수준 A\"]) else 15 if pd.notna(row[\"성취수준 B\"]) else 10\n",
    "    )\n",
    "\n",
    "# 소단원 노드 추가\n",
    "for _, row in data.iterrows():\n",
    "    if pd.notna(row[\"f_schapter_nm\"]):\n",
    "        graph.add_node(\n",
    "            str(row[\"f_schapter_id\"]),\n",
    "            label=row[\"f_schapter_nm\"],\n",
    "            tooltip=\"소단원\",\n",
    "            color=\"lightblue\",\n",
    "            size=10\n",
    "        )\n",
    "        # 상위 단원과 연결\n",
    "        graph.add_edge(\n",
    "            str(row[\"f_mchapter_id\"]),\n",
    "            str(row[\"f_schapter_id\"]),\n",
    "            weight=1,\n",
    "            title=\"소단원 연결\"\n",
    "        )\n",
    "\n",
    "# 엣지 추가 (자기 자신 비교 제외)\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        if i != j and final_sim[i, j] >= threshold:\n",
    "            graph.add_edge(\n",
    "                str(data.iloc[i][\"f_mchapter_id\"]),\n",
    "                str(data.iloc[j][\"f_mchapter_id\"]),\n",
    "                weight=final_sim[i, j],\n",
    "                title=f\"유사도: {final_sim[i, j]:.2f}\"\n",
    "            )\n",
    "\n",
    "# 5. Pyvis 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -3000,\n",
    "      \"centralGravity\": 0.3,\n",
    "      \"springLength\": 200,\n",
    "      \"springConstant\": 0.05\n",
    "    },\n",
    "    \"minVelocity\": 0.1\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# HTML 저장\n",
    "output_file = \"new_knowledge_graph_v2.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"HTML 파일이 '{output_file}'로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사도 기반 + 성취기준 기반 선후행 관계 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated graph saved to new_knowledge_graph_v3.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_nm\", \"f_mchapter_id\", \"성취기준코드\", \"성취기준 내용\", \n",
    "    \"성취수준 A\", \"성취수준 B\", \"성취수준 C\", \"f_schapter_id\", \n",
    "    \"f_schapter_nm\", \"핵심키워드_v2\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data = data.drop_duplicates(subset=[\"f_mchapter_nm\", \"성취기준 내용\", \"핵심키워드_v2\"])\n",
    "data[\"combined_text\"] = (\n",
    "    data[\"f_mchapter_nm\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"성취기준 내용\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"핵심키워드_v2\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True)\n",
    ")\n",
    "data[\"tooltip\"] = (\n",
    "    \"소단원명: \" + data[\"f_schapter_nm\"].fillna(\"\") +\n",
    "    \"<br>성취수준 A: \" + data[\"성취수준 A\"].fillna(\"\") +\n",
    "    \"<br>성취수준 B: \" + data[\"성취수준 B\"].fillna(\"\") +\n",
    "    \"<br>성취수준 C: \" + data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Calculate similarities\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(data[\"combined_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(embeddings.cpu(), embeddings.cpu())\n",
    "\n",
    "# Calculate TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"combined_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "threshold = 0.75\n",
    "\n",
    "# Create the graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes for 성취기준코드 and 단원\n",
    "for _, row in data.iterrows():\n",
    "    graph.add_node(\n",
    "        row[\"성취기준코드\"],\n",
    "        label=row[\"f_mchapter_nm\"] + \" - \" + row[\"성취기준코드\"],\n",
    "        tooltip=row[\"tooltip\"],\n",
    "        color=\"red\",\n",
    "        size=20\n",
    "    )\n",
    "\n",
    "# Add predefined edges based on 성취기준 선후행 관계\n",
    "predefined_edges = [\n",
    "    (\"2수01-01\", \"2수01-02\"),\n",
    "    (\"2수01-02\", \"2수01-03\"),\n",
    "    (\"2수01-03\", \"2수01-04\"),\n",
    "    (\"2수01-05\", \"2수01-06\"),\n",
    "    (\"2수01-06\", \"2수01-07\"),\n",
    "    (\"2수01-07\", \"2수01-08\"),\n",
    "    (\"2수01-08\", \"2수01-09\"),\n",
    "    (\"2수01-10\", \"2수01-11\"),\n",
    "    (\"2수02-01\", \"2수02-02\"),\n",
    "    (\"2수03-01\", \"2수03-02\"),\n",
    "    (\"2수03-03\", \"2수03-04\"),\n",
    "    (\"2수03-04\", \"2수03-05\"),\n",
    "    (\"2수03-06\", \"2수03-07\"),\n",
    "    (\"2수03-07\", \"2수03-08\"),\n",
    "    (\"2수03-08\", \"2수03-09\"),\n",
    "    (\"2수03-10\", \"2수03-11\"),\n",
    "    (\"2수03-11\", \"2수03-12\"),\n",
    "    (\"2수03-12\", \"2수03-13\"),\n",
    "    (\"2수04-01\", \"2수04-02\"),\n",
    "    (\"2수04-02\", \"2수04-03\")\n",
    "]\n",
    "for edge in predefined_edges:\n",
    "    graph.add_edge(edge[0], edge[1], weight=1.0, title=\"선후행 관계\")\n",
    "\n",
    "# Add similarity-based edges (유사도 기반 연결)\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        if i != j and final_sim[i, j] >= threshold:\n",
    "            source = data.iloc[i][\"성취기준코드\"]\n",
    "            target = data.iloc[j][\"성취기준코드\"]\n",
    "            if not graph.has_edge(source, target):\n",
    "                graph.add_edge(\n",
    "                    source,\n",
    "                    target,\n",
    "                    weight=final_sim[i, j],\n",
    "                    title=f\"유사도: {final_sim[i, j]:.2f}\",\n",
    "                    color=\"blue\",\n",
    "                    dash=True\n",
    "                )\n",
    "\n",
    "# Visualize with PyVis\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# Customize physics for better layout\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -2000,\n",
    "      \"centralGravity\": 0.4,\n",
    "      \"springLength\": 200,\n",
    "      \"springConstant\": 0.1\n",
    "    },\n",
    "    \"minVelocity\": 0.5\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"new_knowledge_graph_v3.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Integrated graph saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated graph saved to new_knowledge_graph_v4.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_nm\", \"f_mchapter_id\", \"성취기준코드\", \"성취기준 내용\", \n",
    "    \"성취수준 A\", \"성취수준 B\", \"성취수준 C\", \"f_schapter_id\", \n",
    "    \"f_schapter_nm\", \"핵심키워드_v2\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data = data.drop_duplicates(subset=[\"f_mchapter_nm\", \"성취기준 내용\", \"핵심키워드_v2\"])\n",
    "data[\"combined_text\"] = (\n",
    "    data[\"f_mchapter_nm\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"성취기준 내용\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"핵심키워드_v2\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True)\n",
    ")\n",
    "data[\"tooltip\"] = (\n",
    "    \"소단원명: \" + data[\"f_schapter_nm\"].fillna(\"\") +\n",
    "    \"<br>성취수준 A: \" + data[\"성취수준 A\"].fillna(\"\") +\n",
    "    \"<br>성취수준 B: \" + data[\"성취수준 B\"].fillna(\"\") +\n",
    "    \"<br>성취수준 C: \" + data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Calculate similarities\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(data[\"combined_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(embeddings.cpu(), embeddings.cpu())\n",
    "\n",
    "# Calculate TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"combined_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "threshold = 0.7\n",
    "\n",
    "# Create the graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes for 성취기준코드 and 단원\n",
    "for _, row in data.iterrows():\n",
    "    graph.add_node(\n",
    "        row[\"성취기준코드\"],\n",
    "        label=row[\"f_mchapter_nm\"] + \" - \" + row[\"성취기준코드\"],\n",
    "        tooltip=row[\"tooltip\"],\n",
    "        color=\"red\",\n",
    "        size=20\n",
    "    )\n",
    "\n",
    "# Add predefined edges based on 성취기준 선후행 관계\n",
    "predefined_edges = [\n",
    "    (\"2수01-01\", \"2수01-02\"),\n",
    "    (\"2수01-02\", \"2수01-03\"),\n",
    "    (\"2수01-03\", \"2수01-04\"),\n",
    "    (\"2수01-05\", \"2수01-06\"),\n",
    "    (\"2수01-06\", \"2수01-07\"),\n",
    "    (\"2수01-07\", \"2수01-08\"),\n",
    "    (\"2수01-08\", \"2수01-09\"),\n",
    "    (\"2수01-10\", \"2수01-11\"),\n",
    "    (\"2수02-01\", \"2수02-02\"),\n",
    "    (\"2수03-01\", \"2수03-02\"),\n",
    "    (\"2수03-03\", \"2수03-04\"),\n",
    "    (\"2수03-04\", \"2수03-05\"),\n",
    "    (\"2수03-06\", \"2수03-07\"),\n",
    "    (\"2수03-07\", \"2수03-08\"),\n",
    "    (\"2수03-08\", \"2수03-09\"),\n",
    "    (\"2수03-10\", \"2수03-11\"),\n",
    "    (\"2수03-11\", \"2수03-12\"),\n",
    "    (\"2수03-12\", \"2수03-13\"),\n",
    "    (\"2수04-01\", \"2수04-02\"),\n",
    "    (\"2수04-02\", \"2수04-03\")\n",
    "]\n",
    "for edge in predefined_edges:\n",
    "    graph.add_edge(edge[0], edge[1], weight=1.0, title=\"선후행 관계\")\n",
    "\n",
    "# Add similarity-based edges (유사도 기반 연결)\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        if i != j and final_sim[i, j] >= threshold:\n",
    "            source = data.iloc[i][\"성취기준코드\"]\n",
    "            target = data.iloc[j][\"성취기준코드\"]\n",
    "            if not graph.has_edge(source, target):\n",
    "                graph.add_edge(\n",
    "                    source,\n",
    "                    target,\n",
    "                    weight=final_sim[i, j],\n",
    "                    title=f\"유사도: {final_sim[i, j]:.2f}\",\n",
    "                    color=\"blue\",\n",
    "                    dash=True\n",
    "                )\n",
    "\n",
    "# Visualize with PyVis\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# Customize physics for better layout\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -2000,\n",
    "      \"centralGravity\": 0.4,\n",
    "      \"springLength\": 200,\n",
    "      \"springConstant\": 0.1\n",
    "    },\n",
    "    \"minVelocity\": 0.5\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"new_knowledge_graph_v4.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Integrated graph saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2+v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated graph saved to new_knowledge_graph_v5.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_nm\", \"f_mchapter_id\", \"성취기준코드\", \"성취기준 내용\", \n",
    "    \"성취수준 A\", \"성취수준 B\", \"성취수준 C\", \"f_schapter_id\", \n",
    "    \"f_schapter_nm\", \"핵심키워드_v2\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data = data.drop_duplicates(subset=[\"f_mchapter_nm\", \"성취기준 내용\", \"핵심키워드_v2\"])\n",
    "data[\"combined_text\"] = (\n",
    "    data[\"f_mchapter_nm\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"성취기준 내용\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True) +\n",
    "    \" \" +\n",
    "    data[\"핵심키워드_v2\"].str.lower().str.replace(r\"[^a-z가-힣0-9\\s]\", \"\", regex=True)\n",
    ")\n",
    "data[\"tooltip\"] = (\n",
    "    \"소단원명: \" + data[\"f_schapter_nm\"].fillna(\"\") +\n",
    "    \"<br>성취수준 A: \" + data[\"성취수준 A\"].fillna(\"\") +\n",
    "    \"<br>성취수준 B: \" + data[\"성취수준 B\"].fillna(\"\") +\n",
    "    \"<br>성취수준 C: \" + data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Calculate similarities\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(data[\"combined_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(embeddings.cpu(), embeddings.cpu()).astype('float64')  # Ensure float64\n",
    "\n",
    "# Combine similarities\n",
    "threshold = 0.85  # Threshold for similarity\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes for 중단원\n",
    "for _, row in data.iterrows():\n",
    "    graph.add_node(\n",
    "        row[\"성취기준코드\"],\n",
    "        label=row[\"f_mchapter_nm\"] + \" - \" + row[\"성취기준코드\"],\n",
    "        tooltip=row[\"tooltip\"],\n",
    "        color=\"green\",\n",
    "        size=20\n",
    "    )\n",
    "\n",
    "# Add predefined edges based on 성취기준 선후행 관계\n",
    "predefined_edges = [\n",
    "    (\"2수01-01\", \"2수01-02\"),\n",
    "    (\"2수01-02\", \"2수01-03\"),\n",
    "    (\"2수01-03\", \"2수01-04\"),\n",
    "    (\"2수01-05\", \"2수01-06\"),\n",
    "    (\"2수01-06\", \"2수01-07\"),\n",
    "    (\"2수01-07\", \"2수01-08\"),\n",
    "    (\"2수01-08\", \"2수01-09\"),\n",
    "    (\"2수01-10\", \"2수01-11\"),\n",
    "    (\"2수02-01\", \"2수02-02\"),\n",
    "    (\"2수03-01\", \"2수03-02\"),\n",
    "    (\"2수03-03\", \"2수03-04\"),\n",
    "    (\"2수03-04\", \"2수03-05\"),\n",
    "    (\"2수03-06\", \"2수03-07\"),\n",
    "    (\"2수03-07\", \"2수03-08\"),\n",
    "    (\"2수03-08\", \"2수03-09\"),\n",
    "    (\"2수03-10\", \"2수03-11\"),\n",
    "    (\"2수03-11\", \"2수03-12\"),\n",
    "    (\"2수03-12\", \"2수03-13\"),\n",
    "    (\"2수04-01\", \"2수04-02\"),\n",
    "    (\"2수04-02\", \"2수04-03\")\n",
    "]\n",
    "for edge in predefined_edges:\n",
    "    graph.add_edge(edge[0], edge[1], weight=1.0, title=\"선후행 관계\", color=\"blue\")\n",
    "\n",
    "# Add similarity-based edges\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):  # Only forward connections allowed\n",
    "        if bert_sim[i, j] >= threshold:\n",
    "            source = data.iloc[i][\"성취기준코드\"]\n",
    "            target = data.iloc[j][\"성취기준코드\"]\n",
    "            graph.add_edge(\n",
    "                source,\n",
    "                target,\n",
    "                weight=float(bert_sim[i, j]),  # Ensure float is JSON serializable\n",
    "                title=f\"유사도: {bert_sim[i, j]:.2f}\",\n",
    "                color=\"red\"\n",
    "            )\n",
    "\n",
    "# Remove self-loops and duplicated edges\n",
    "edges_to_remove = []\n",
    "for u, v in graph.edges():\n",
    "    if u == v:  # Remove self-loops\n",
    "        edges_to_remove.append((u, v))\n",
    "for edge in edges_to_remove:\n",
    "    graph.remove_edge(*edge)\n",
    "\n",
    "# Visualize with PyVis\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# Customize physics for better layout\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -3000,\n",
    "      \"centralGravity\": 0.3,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.05\n",
    "    },\n",
    "    \"minVelocity\": 0.5\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 20\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"new_knowledge_graph_v5.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Integrated graph saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized graph saved to new_knowledge_graph_v6.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\"f_mchapter_nm\", \"성취기준코드\", \"성취기준 내용\", \"핵심키워드_v2\"]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Combine text for similarity calculation\n",
    "data[\"combined_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"핵심키워드_v2\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Sort data by 성취기준코드\n",
    "data = data.sort_values(by=\"성취기준코드\").reset_index(drop=True)\n",
    "\n",
    "# Perform similarity-based analysis\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(data[\"combined_text\"].tolist(), convert_to_tensor=True)\n",
    "similarity_matrix = cosine_similarity(embeddings.cpu(), embeddings.cpu())\n",
    "\n",
    "# Generate 성취기준 흐름 기반 edges\n",
    "flow_edges = []\n",
    "for i in range(len(data) - 1):\n",
    "    flow_edges.append((data.iloc[i][\"성취기준코드\"], data.iloc[i + 1][\"성취기준코드\"], \"선후행 관계\"))\n",
    "\n",
    "# Generate 유사도 기반 edges\n",
    "threshold = 0.75  # Set a high threshold for similarity\n",
    "similarity_edges = []\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):  # Only forward connections allowed\n",
    "        if similarity_matrix[i, j] >= threshold:\n",
    "            similarity_edges.append((data.iloc[i][\"성취기준코드\"], data.iloc[j][\"성취기준코드\"], \"유사도 기반 연결\"))\n",
    "\n",
    "# Combine edges\n",
    "all_edges = flow_edges + similarity_edges\n",
    "\n",
    "# Map 성취기준코드 to 중단원명\n",
    "code_to_chapter = data.set_index(\"성취기준코드\")[\"f_mchapter_nm\"].to_dict()\n",
    "\n",
    "# Create the graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes for 중단원\n",
    "unique_mchapters = data[\"f_mchapter_nm\"].unique()\n",
    "for chapter in unique_mchapters:\n",
    "    graph.add_node(\n",
    "        chapter,\n",
    "        label=chapter,\n",
    "        color=\"green\",\n",
    "        size=30\n",
    "    )\n",
    "\n",
    "# Add edges to the graph\n",
    "for source, target, edge_type in all_edges:\n",
    "    source_chapter = code_to_chapter[source]\n",
    "    target_chapter = code_to_chapter[target]\n",
    "    if source_chapter != target_chapter:  # Avoid self-loops\n",
    "        graph.add_edge(\n",
    "            source_chapter, target_chapter,\n",
    "            color=\"blue\" if edge_type == \"선후행 관계\" else \"red\",\n",
    "            title=edge_type\n",
    "        )\n",
    "\n",
    "# Visualize with PyVis\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# Customize physics for better layout\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -2000,\n",
    "      \"centralGravity\": 0.4,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.05\n",
    "    },\n",
    "    \"minVelocity\": 0.5\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"new_knowledge_graph_v6.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Optimized graph saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성취기준 코드 흐름으로만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with chapter connections by 성취기준코드 flow saved to chapter_by_code_flow_graph.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\"f_mchapter_nm\", \"성취기준코드\"]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess 중단원명\n",
    "data[\"f_mchapter_nm\"] = (\n",
    "    data[\"f_mchapter_nm\"]\n",
    "    .str.strip()  # 공백 제거\n",
    "    .str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)  # 특수문자 제거\n",
    ")\n",
    "\n",
    "# Sort data by 성취기준코드 to establish flow\n",
    "data = data.sort_values(by=\"성취기준코드\").reset_index(drop=True)\n",
    "\n",
    "# Map 성취기준코드 to 중단원명\n",
    "code_to_chapter = data.set_index(\"성취기준코드\")[\"f_mchapter_nm\"].to_dict()\n",
    "\n",
    "# Generate edges based on 성취기준코드 flow\n",
    "edges = []\n",
    "previous_chapter = None\n",
    "for _, row in data.iterrows():\n",
    "    current_chapter = row[\"f_mchapter_nm\"]\n",
    "    if previous_chapter and previous_chapter != current_chapter:\n",
    "        edges.append((previous_chapter, current_chapter))\n",
    "    previous_chapter = current_chapter\n",
    "\n",
    "# Extract unique 중단원명\n",
    "unique_mchapters = data[\"f_mchapter_nm\"].drop_duplicates().tolist()\n",
    "\n",
    "# Create the graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes for 중단원명\n",
    "for chapter in unique_mchapters:\n",
    "    graph.add_node(\n",
    "        chapter,\n",
    "        label=chapter,\n",
    "        color=\"green\",\n",
    "        size=30\n",
    "    )\n",
    "\n",
    "# Add edges for 중단원 선후행 관계\n",
    "for edge in edges:\n",
    "    graph.add_edge(\n",
    "        edge[0], edge[1],\n",
    "        weight=1.0,\n",
    "        color=\"blue\",\n",
    "        title=\"성취기준코드 흐름 기반 중단원 선후행 관계\"\n",
    "    )\n",
    "\n",
    "# Add edges to ensure all nodes are connected if needed\n",
    "connected_components = list(nx.weakly_connected_components(graph))\n",
    "if len(connected_components) > 1:\n",
    "    for i in range(len(connected_components) - 1):\n",
    "        source = list(connected_components[i])[0]\n",
    "        target = list(connected_components[i + 1])[0]\n",
    "        graph.add_edge(\n",
    "            source, target,\n",
    "            weight=0.1,\n",
    "            color=\"gray\",\n",
    "            title=\"추가 연결\"\n",
    "        )\n",
    "\n",
    "# Visualize with PyVis\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# Customize physics for better layout\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -2000,\n",
    "      \"centralGravity\": 0.4,\n",
    "      \"springLength\": 200,\n",
    "      \"springConstant\": 0.1\n",
    "    },\n",
    "    \"minVelocity\": 0.5\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"chapter_by_code_flow_graph.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Graph with chapter connections by 성취기준코드 flow saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with chapter connections by f_mchapter_id saved to chapter_by_code_flow_graph_with_id.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\"f_mchapter_id\", \"f_mchapter_nm\", \"성취기준코드\"]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess 중단원명\n",
    "data[\"f_mchapter_nm\"] = (\n",
    "    data[\"f_mchapter_nm\"]\n",
    "    .str.strip()  # 공백 제거\n",
    "    .str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)  # 특수문자 제거\n",
    ")\n",
    "\n",
    "# Sort data by 성취기준코드 to establish flow\n",
    "data = data.sort_values(by=\"성취기준코드\").reset_index(drop=True)\n",
    "\n",
    "# Map 성취기준코드 to 중단원 ID and Name\n",
    "code_to_id = data.set_index(\"성취기준코드\")[\"f_mchapter_id\"].to_dict()\n",
    "id_to_name = data.set_index(\"f_mchapter_id\")[\"f_mchapter_nm\"].to_dict()\n",
    "\n",
    "# Generate edges based on 성취기준코드 flow\n",
    "edges = []\n",
    "previous_id = None\n",
    "for _, row in data.iterrows():\n",
    "    current_id = row[\"f_mchapter_id\"]\n",
    "    if previous_id and previous_id != current_id:\n",
    "        edges.append((previous_id, current_id))\n",
    "    previous_id = current_id\n",
    "\n",
    "# Extract unique 중단원 IDs\n",
    "unique_ids = data[\"f_mchapter_id\"].drop_duplicates().tolist()\n",
    "\n",
    "# Create the graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes for 중단원 ID with labels as 중단원명\n",
    "for node_id in unique_ids:\n",
    "    graph.add_node(\n",
    "        node_id,\n",
    "        label=id_to_name[node_id],\n",
    "        color=\"green\",\n",
    "        size=30\n",
    "    )\n",
    "\n",
    "# Add edges for 중단원 선후행 관계\n",
    "for edge in edges:\n",
    "    graph.add_edge(\n",
    "        edge[0], edge[1],\n",
    "        weight=1.0,\n",
    "        color=\"blue\",\n",
    "        title=\"성취기준코드 흐름 기반 중단원 선후행 관계\"\n",
    "    )\n",
    "\n",
    "# Add edges to ensure all nodes are connected if needed\n",
    "connected_components = list(nx.weakly_connected_components(graph))\n",
    "if len(connected_components) > 1:\n",
    "    for i in range(len(connected_components) - 1):\n",
    "        source = list(connected_components[i])[0]\n",
    "        target = list(connected_components[i + 1])[0]\n",
    "        graph.add_edge(\n",
    "            source, target,\n",
    "            weight=0.1,\n",
    "            color=\"gray\",\n",
    "            title=\"추가 연결\"\n",
    "        )\n",
    "\n",
    "# Visualize with PyVis\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# Customize physics for better layout\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -2000,\n",
    "      \"centralGravity\": 0.4,\n",
    "      \"springLength\": 200,\n",
    "      \"springConstant\": 0.1\n",
    "    },\n",
    "    \"minVelocity\": 0.5\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"chapter_by_code_flow_graph_with_id.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Graph with chapter connections by f_mchapter_id saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위의 코드로 돌린 후, 중단원명이 다 표현되는지 확인하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프에 포함된 중단원 개수: 94\n",
      "그래프에 포함된 중단원: ['14201779', '14201780', '14201781', '14201782', '14201783', '14201784', '14201785', '14201786', '14201787', '14201788', '14201789', '14201790', '14201791', '14201792', '14201793', '14201794', '14201795', '14201796', '14201797', '14201798', '14201799', '14201800', '14201801', '14201802', '14201803', '14201804', '14201805', '14201806', '14201807', '14201808', '14201809', '14201810', '14201811', '14201812', '14201813', '14201814', '14201815', '14201816', '14201817', '14201818', '14201819', '14201820', '14201821', '14201857', '14201858', '14201859', '14201860', '14201861', '14201862', '14201863', '14201864', '14201865', '14201866', '14201867', '14201868', '14201869', '14201870', '14201871', '14201872', '14201873', '14201874', '14201875', '14201876', '14201877', '14201878', '14201879', '14201880', '14201881', '14201882', '14201883', '14201884', '14201885', '14201886', '14201887', '14201888', '14201889', '14201890', '14201891', '14201892', '14201893', '14201894', '14201895', '14201896', '14201897', '14201898', '14201899', '14201900', '14201901', '14201902', '14201903', '14201904', '14201905', '14201906', '14201907']\n",
      "데이터에서 고유한 중단원 개수: 84\n",
      "데이터에서 고유한 중단원: ['12345알아보기' '6789알아보기' '9까지수의순서' '1만큼더큰수와1만큼더작은수0알아보기' '두수의크기비교'\n",
      " '여러가지모양찾아보기' '여러가지모양알아보기' '2345를모으고가르기' '6789를모으고가르기' '덧셈과뺄셈이야기만들기' '덧셈'\n",
      " '뺄셈' '덧셈과뺄셈' '길이비교하기' '무게비교하기' '넓이비교하기' '담을수있는양비교하기' '높이비교하기' '키비교하기'\n",
      " '10알아보기' '십몇알아보기' '몇십과몇십몇을알아보기' '50까지의수의순서' '백과몇백알아보기' '세자리수알아보기' '뛰어세기'\n",
      " '도형' '쌓기나무' '덧셈과뺄셈의관계' '의값구하기' '세수의계산' '여러가지단위길이로재기' '자로길이재기'\n",
      " '길이를어림해보고재어보기' '분류하기' '묶어세기' '곱셈식알아보기' '곱셈식을활용하기' '몇십알아보기' '99까지의수알아보기'\n",
      " '수의순서알아보기' '두수의크기비교하기' '여러개의수의크기비교하기' '짝수와홀수' '한자리세수의계산' '두수를더하기'\n",
      " '10이되는더하기' '10에서빼기' '10을만들어더하기' '여러가지모양만들기' '몇시알아보기' '몇시30분알아보기'\n",
      " '몇시몇시30분의응용' '10을이용하여모으기와가르기' '받아올림이있는덧셈' '받아내림이있는뺄셈' '규칙찾기' '규칙만들기1'\n",
      " '규칙만들기2' '규칙찾기수' '덧셈하기1' '덧셈하기2' '덧셈하기3' '덧셈하기4' '뺄셈하기1' '뺄셈하기2' '뺄셈하기3'\n",
      " '뺄셈하기4' '1000과몇천알아보기' '네자리수알아보기' '2단3단5단6단곱셈구구' '4단7단8단9단곱셈구구'\n",
      " '1단곱셈구구와0의곱' '곱셈표' '곱셈구구를활용하기' '길이알아보기' '길이의합' '길이의차' '길이어림하기' '시각과시간'\n",
      " '하루의시간알아보기' '달력알아보기' '표로나타내기' '그래프로나타내기']\n",
      "누락된 중단원: {'무게비교하기', '덧셈과뺄셈의관계', '받아내림이있는뺄셈', '두수를더하기', '두수의크기비교', '1단곱셈구구와0의곱', '여러가지모양알아보기', '키비교하기', '4단7단8단9단곱셈구구', '여러가지모양찾아보기', '몇시알아보기', '길이알아보기', '10을만들어더하기', '십몇알아보기', '여러개의수의크기비교하기', '세수의계산', '곱셈식알아보기', '표로나타내기', '덧셈하기4', '곱셈식을활용하기', '하루의시간알아보기', '두수의크기비교하기', '담을수있는양비교하기', '자로길이재기', '규칙만들기1', '분류하기', '2단3단5단6단곱셈구구', '규칙만들기2', '시각과시간', '50까지의수의순서', '묶어세기', '1만큼더큰수와1만큼더작은수0알아보기', '길이의합', '네자리수알아보기', '뺄셈', '길이비교하기', '덧셈하기3', '몇시30분알아보기', '규칙찾기수', '몇십알아보기', '그래프로나타내기', '뺄셈하기1', '넓이비교하기', '몇시몇시30분의응용', '짝수와홀수', '10에서빼기', '수의순서알아보기', '뺄셈하기2', '백과몇백알아보기', '달력알아보기', '한자리세수의계산', '6789알아보기', '곱셈표', '규칙찾기', '덧셈과뺄셈', '여러가지모양만들기', '도형', '의값구하기', '받아올림이있는덧셈', '길이어림하기', '세자리수알아보기', '길이의차', '뛰어세기', '덧셈하기2', '몇십과몇십몇을알아보기', '6789를모으고가르기', '덧셈하기1', '10이되는더하기', '10을이용하여모으기와가르기', '높이비교하기', '99까지의수알아보기', '쌓기나무', '덧셈', '10알아보기', '뺄셈하기4', '12345알아보기', '뺄셈하기3', '곱셈구구를활용하기', '1000과몇천알아보기', '길이를어림해보고재어보기', '덧셈과뺄셈이야기만들기', '9까지수의순서', '여러가지단위길이로재기', '2345를모으고가르기'}\n"
     ]
    }
   ],
   "source": [
    "# 그래프의 노드 이름 확인\n",
    "graph_nodes = [node for node in graph.nodes]\n",
    "print(\"그래프에 포함된 중단원 개수:\", len(graph_nodes))\n",
    "print(\"그래프에 포함된 중단원:\", graph_nodes)\n",
    "\n",
    "# 데이터에서 고유한 중단원 확인\n",
    "unique_mchapters = data[\"f_mchapter_nm\"].unique()\n",
    "print(\"데이터에서 고유한 중단원 개수:\", len(unique_mchapters))\n",
    "print(\"데이터에서 고유한 중단원:\", unique_mchapters)\n",
    "\n",
    "# 누락된 중단원 확인\n",
    "missing_chapters = set(unique_mchapters) - set(graph_nodes)\n",
    "if missing_chapters:\n",
    "    print(\"누락된 중단원:\", missing_chapters)\n",
    "else:\n",
    "    print(\"모든 중단원이 그래프에 포함되어 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-BERT와 TF-IDF 입력 데이터 분리 + 유사도 가장 높은 거 하나만 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with integrated flow and similarity saved to final_chapter_graph.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 성취기준 흐름 기반 관계 생성\n",
    "flow_edges = []\n",
    "previous_id = None\n",
    "for _, row in data.iterrows():\n",
    "    current_id = row[\"f_mchapter_id\"]\n",
    "    if previous_id and previous_id != current_id:\n",
    "        flow_edges.append((previous_id, current_id))\n",
    "    previous_id = current_id\n",
    "\n",
    "# 유사도 기반 관계 생성 (가장 높은 유사도 하나만 유지)\n",
    "threshold = 0.95\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "for chapter_id, chapter_name in zip(data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"]):\n",
    "    graph.add_node(\n",
    "        str(chapter_id),  # ID는 문자열로 변환\n",
    "        label=chapter_name,\n",
    "        color=\"green\",\n",
    "        size=30\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for source, target in final_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"blue\",\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# PyVis로 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true, \n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true, \n",
    "      \"iterations\": 1000, \n",
    "      \"fit\": true\n",
    "    },\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -8000, \n",
    "      \"centralGravity\": 0.3, \n",
    "      \"springLength\": 500, \n",
    "      \"springConstant\": 0.05\n",
    "    },\n",
    "    \"minVelocity\": 0.1\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 20\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"final_chapter_graph.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Graph with integrated flow and similarity saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-BERT와 TF-IDF 입력 데이터 분리 + 유사도 가장 높은 거 하나만 연결 + 학년학기별 색상 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with integrated flow and similarity saved to final_chapter_graph2.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 성취기준 흐름 기반 관계 생성\n",
    "flow_edges = []\n",
    "previous_id = None\n",
    "for _, row in data.iterrows():\n",
    "    current_id = row[\"f_mchapter_id\"]\n",
    "    if previous_id and previous_id != current_id:\n",
    "        flow_edges.append((previous_id, current_id))\n",
    "    previous_id = current_id\n",
    "\n",
    "# 유사도 기반 관계 생성 (가장 높은 유사도 하나만 유지)\n",
    "threshold = 0.95\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 노드 색상 매핑\n",
    "def get_node_color(subject_id):\n",
    "    color_map = {\n",
    "        2212: \"red\",\n",
    "        2213: \"blue\",\n",
    "        2214: \"green\",\n",
    "        2215: \"yellow\"\n",
    "    }\n",
    "    return color_map.get(subject_id, \"gray\")\n",
    "\n",
    "# 노드 추가\n",
    "for chapter_id, chapter_name, subject_id in zip(data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"], data[\"f_subject_id\"]):\n",
    "    graph.add_node(\n",
    "        str(chapter_id),  # ID는 문자열로 변환\n",
    "        label=chapter_name,\n",
    "        color=get_node_color(subject_id),\n",
    "        size=30\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for source, target in final_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"blue\",\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# PyVis로 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true, \n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true, \n",
    "      \"iterations\": 1000, \n",
    "      \"fit\": true\n",
    "    },\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -8000, \n",
    "      \"centralGravity\": 0.3, \n",
    "      \"springLength\": 500, \n",
    "      \"springConstant\": 0.05\n",
    "    },\n",
    "    \"minVelocity\": 0.1\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 20\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"final_chapter_graph2.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Graph with integrated flow and similarity saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final_chapter_graph2 + 색상별 즉 학년 학기별 군집화 = final_chapter_graph3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with integrated flow and similarity saved to final_chapter_graph3.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 성취기준 흐름 기반 관계 생성\n",
    "flow_edges = []\n",
    "previous_id = None\n",
    "for _, row in data.iterrows():\n",
    "    current_id = row[\"f_mchapter_id\"]\n",
    "    if previous_id and previous_id != current_id:\n",
    "        flow_edges.append((previous_id, current_id))\n",
    "    previous_id = current_id\n",
    "\n",
    "# 유사도 기반 관계 생성\n",
    "threshold = 0.95\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 색상 및 그룹 설정\n",
    "def get_node_color(subject_id):\n",
    "    color_map = {\n",
    "        2212: \"#FF4444\",  # 더 선명한 빨강\n",
    "        2213: \"#4444FF\",  # 더 선명한 파랑\n",
    "        2214: \"#44FF44\",  # 더 선명한 초록\n",
    "        2215: \"#FFFF44\"   # 더 선명한 노랑\n",
    "    }\n",
    "    return color_map.get(subject_id, \"#GRAY\")\n",
    "\n",
    "# 노드를 subject_id별로 그룹화\n",
    "grouped_data = data.groupby(\"f_subject_id\")\n",
    "y_positions = {sid: idx * 100 for idx, sid in enumerate(data[\"f_subject_id\"].unique())}\n",
    "\n",
    "# 노드 추가 (위치 정보 포함)\n",
    "for chapter_id, chapter_name, subject_id in zip(data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"], data[\"f_subject_id\"]):\n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        color=get_node_color(subject_id),\n",
    "        size=30,\n",
    "        group=str(subject_id)  # 그룹 설정\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for source, target in final_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"#aaaaff\",  # 연한 파란색으로 변경\n",
    "        width=1,\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# PyVis로 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -100,\n",
    "      \"centralGravity\": 0.01,\n",
    "      \"springLength\": 200,\n",
    "      \"springConstant\": 0.08,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"groups\": {\n",
    "    \"2212\": {\"color\": \"#FF4444\"},\n",
    "    \"2213\": {\"color\": \"#4444FF\"},\n",
    "    \"2214\": {\"color\": \"#44FF44\"},\n",
    "    \"2215\": {\"color\": \"#FFFF44\"}\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# Save visualization\n",
    "output_file = \"final_chapter_graph3.html\"\n",
    "net.write_html(output_file)\n",
    "print(f\"Graph with integrated flow and similarity saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert embedding으로 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER2\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "군집화 결과 분석:\n",
      "\n",
      "클러스터 0 (11 개 노드):\n",
      "chapter_name  subject_id\n",
      "     두수의크기비교        2212\n",
      "       덧셈과뺄셈        2212\n",
      "    덧셈과뺄셈의관계        2214\n",
      "       의값구하기        2214\n",
      "       세수의계산        2214\n",
      "   받아올림이있는덧셈        2213\n",
      "   받아내림이있는뺄셈        2213\n",
      "       덧셈하기2        2213\n",
      "       덧셈하기3        2213\n",
      "       뺄셈하기2        2213\n",
      "       뺄셈하기3        2213\n",
      "\n",
      "클러스터 1 (31 개 노드):\n",
      "       chapter_name  subject_id\n",
      "          12345알아보기        2212\n",
      "           6789알아보기        2212\n",
      "1만큼더큰수와1만큼더작은수0알아보기        2212\n",
      "        덧셈과뺄셈이야기만들기        2212\n",
      "                 덧셈        2212\n",
      "                 뺄셈        2212\n",
      "             10알아보기        2212\n",
      "             십몇알아보기        2212\n",
      "               묶어세기        2214\n",
      "           곱셈식을활용하기        2214\n",
      "             몇십알아보기        2213\n",
      "         99까지의수알아보기        2213\n",
      "           한자리세수의계산        2213\n",
      "             두수를더하기        2213\n",
      "           10이되는더하기        2213\n",
      "             10에서빼기        2213\n",
      "          10을만들어더하기        2213\n",
      "          몇시30분알아보기        2213\n",
      "         몇시몇시30분의응용        2213\n",
      "              덧셈하기1        2213\n",
      "              덧셈하기4        2213\n",
      "              뺄셈하기1        2213\n",
      "              뺄셈하기4        2213\n",
      "        1000과몇천알아보기        2215\n",
      "         1단곱셈구구와0의곱        2215\n",
      "                곱셈표        2215\n",
      "          곱셈구구를활용하기        2215\n",
      "               길이의합        2215\n",
      "               길이의차        2215\n",
      "          하루의시간알아보기        2215\n",
      "             달력알아보기        2215\n",
      "\n",
      "클러스터 2 (10 개 노드):\n",
      "  chapter_name  subject_id\n",
      "   2345를모으고가르기        2212\n",
      "   6789를모으고가르기        2212\n",
      "   몇십과몇십몇을알아보기        2212\n",
      "      백과몇백알아보기        2214\n",
      "      세자리수알아보기        2214\n",
      "         짝수와홀수        2213\n",
      "        몇시알아보기        2213\n",
      "10을이용하여모으기와가르기        2213\n",
      "      네자리수알아보기        2215\n",
      "         시각과시간        2215\n",
      "\n",
      "클러스터 3 (32 개 노드):\n",
      "chapter_name  subject_id\n",
      "     9까지수의순서        2212\n",
      "  여러가지모양찾아보기        2212\n",
      "  여러가지모양알아보기        2212\n",
      "      길이비교하기        2212\n",
      "      무게비교하기        2212\n",
      "      넓이비교하기        2212\n",
      "  담을수있는양비교하기        2212\n",
      "      높이비교하기        2212\n",
      "       키비교하기        2212\n",
      "   50까지의수의순서        2212\n",
      "        뛰어세기        2214\n",
      "          도형        2214\n",
      "        쌓기나무        2214\n",
      " 여러가지단위길이로재기        2214\n",
      "      자로길이재기        2214\n",
      "길이를어림해보고재어보기        2214\n",
      "        분류하기        2214\n",
      "     곱셈식알아보기        2214\n",
      "    수의순서알아보기        2213\n",
      "   두수의크기비교하기        2213\n",
      "여러개의수의크기비교하기        2213\n",
      "   여러가지모양만들기        2213\n",
      "        규칙찾기        2213\n",
      "      규칙만들기1        2213\n",
      "      규칙만들기2        2213\n",
      "       규칙찾기수        2213\n",
      "2단3단5단6단곱셈구구        2215\n",
      "4단7단8단9단곱셈구구        2215\n",
      "      길이알아보기        2215\n",
      "      길이어림하기        2215\n",
      "      표로나타내기        2215\n",
      "    그래프로나타내기        2215\n",
      "\n",
      "정리된 군집화 결과를 clustered_results.csv에 저장했습니다.\n",
      "\n",
      "Graph with embedding-based clustering saved to final_chapter_graph_clustered.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# BERT 임베딩 생성\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "embeddings_np = bert_embeddings.cpu().numpy()\n",
    "\n",
    "# K-means 군집화\n",
    "n_clusters = 4  # subject_id 개수와 동일하게 설정\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(embeddings_np)\n",
    "\n",
    "# t-SNE로 차원 축소 (전체 데이터에 대해 한 번만 실행)\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=min(30, len(embeddings_np) - 1),  # perplexity 값 조정\n",
    "    random_state=42,\n",
    "    n_iter=1000\n",
    ")\n",
    "embeddings_2d = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "# 성취기준 흐름 기반 관계 생성\n",
    "flow_edges = []\n",
    "previous_id = None\n",
    "for _, row in data.iterrows():\n",
    "    current_id = row[\"f_mchapter_id\"]\n",
    "    if previous_id and previous_id != current_id:\n",
    "        flow_edges.append((previous_id, current_id))\n",
    "    previous_id = current_id\n",
    "\n",
    "# 유사도 기반 관계 생성\n",
    "cosine_sim = cosine_similarity(embeddings_np)\n",
    "threshold = 0.95\n",
    "similarity_edges = []\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if cosine_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 군집별 색상 매핑\n",
    "cluster_colors = ['#FF4444', '#4444FF', '#44FF44', '#FFFF44']\n",
    "\n",
    "# 노드 추가 (임베딩 기반 위치 정보 포함)\n",
    "for idx, (chapter_id, chapter_name) in enumerate(zip(data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"])):\n",
    "    # t-SNE 좌표를 기반으로 위치 설정\n",
    "    x, y = embeddings_2d[idx]\n",
    "    \n",
    "    # 스케일 조정 (더 넓은 공간에 분포하도록)\n",
    "    x = x * 10\n",
    "    y = y * 10\n",
    "    \n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        color=cluster_colors[cluster_labels[idx]],\n",
    "        size=30,\n",
    "        x=float(x),\n",
    "        y=float(y),\n",
    "        group=str(cluster_labels[idx])\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for source, target in final_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"#aaaaff\",\n",
    "        width=1,\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# PyVis로 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"groups\": {\n",
    "    \"0\": {\"color\": \"#FF4444\"},\n",
    "    \"1\": {\"color\": \"#4444FF\"},\n",
    "    \"2\": {\"color\": \"#44FF44\"},\n",
    "    \"3\": {\"color\": \"#FFFF44\"}\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# 군집화 결과 데이터프레임 생성\n",
    "cluster_info = pd.DataFrame({\n",
    "    'chapter_id': data['f_mchapter_id'],\n",
    "    'chapter_name': data['f_mchapter_nm'],\n",
    "    'subject_id': data['f_subject_id'],\n",
    "    'cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# 중복 제거 (chapter_name 기준으로 고유값만 유지)\n",
    "cluster_info_unique = cluster_info.drop_duplicates(subset=['chapter_name'])\n",
    "\n",
    "# 군집별 데이터 요약 출력\n",
    "print(\"\\n군집화 결과 분석:\")\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = cluster_info_unique[cluster_info_unique['cluster'] == cluster]\n",
    "    print(f\"\\n클러스터 {cluster} ({len(cluster_data)} 개 노드):\")\n",
    "    print(cluster_data[['chapter_name', 'subject_id']].to_string(index=False))\n",
    "\n",
    "# 저장할 경우 (옵션)\n",
    "output_file = \"clustered_results.csv\"\n",
    "cluster_info_unique.to_csv(output_file, index=False)\n",
    "print(f\"\\n정리된 군집화 결과를 {output_file}에 저장했습니다.\")\n",
    "\n",
    "\n",
    "# Save visualization\n",
    "output_file_html = \"final_chapter_graph_clustered.html\"\n",
    "net.write_html(output_file_html)\n",
    "print(f\"\\nGraph with embedding-based clustering saved to {output_file_html}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래 유사도 검사 + k-means 고정 & n_init 수 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER2\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "군집화 결과 분석:\n",
      "\n",
      "클러스터 0 (61 개 노드):\n",
      "       chapter_name  subject_id\n",
      "          12345알아보기        2212\n",
      "           6789알아보기        2212\n",
      "            9까지수의순서        2212\n",
      "1만큼더큰수와1만큼더작은수0알아보기        2212\n",
      "         여러가지모양찾아보기        2212\n",
      "         여러가지모양알아보기        2212\n",
      "        덧셈과뺄셈이야기만들기        2212\n",
      "                 덧셈        2212\n",
      "                 뺄셈        2212\n",
      "             길이비교하기        2212\n",
      "             무게비교하기        2212\n",
      "             넓이비교하기        2212\n",
      "         담을수있는양비교하기        2212\n",
      "             높이비교하기        2212\n",
      "              키비교하기        2212\n",
      "             10알아보기        2212\n",
      "             십몇알아보기        2212\n",
      "          50까지의수의순서        2212\n",
      "               뛰어세기        2214\n",
      "                 도형        2214\n",
      "               쌓기나무        2214\n",
      "        여러가지단위길이로재기        2214\n",
      "             자로길이재기        2214\n",
      "       길이를어림해보고재어보기        2214\n",
      "               분류하기        2214\n",
      "               묶어세기        2214\n",
      "            곱셈식알아보기        2214\n",
      "           곱셈식을활용하기        2214\n",
      "             몇십알아보기        2213\n",
      "         99까지의수알아보기        2213\n",
      "           수의순서알아보기        2213\n",
      "          두수의크기비교하기        2213\n",
      "       여러개의수의크기비교하기        2213\n",
      "           한자리세수의계산        2213\n",
      "             두수를더하기        2213\n",
      "           10이되는더하기        2213\n",
      "             10에서빼기        2213\n",
      "          10을만들어더하기        2213\n",
      "          여러가지모양만들기        2213\n",
      "          몇시30분알아보기        2213\n",
      "         몇시몇시30분의응용        2213\n",
      "               규칙찾기        2213\n",
      "             규칙만들기1        2213\n",
      "             규칙만들기2        2213\n",
      "              규칙찾기수        2213\n",
      "              덧셈하기1        2213\n",
      "              덧셈하기4        2213\n",
      "              뺄셈하기1        2213\n",
      "              뺄셈하기4        2213\n",
      "        1000과몇천알아보기        2215\n",
      "       2단3단5단6단곱셈구구        2215\n",
      "       4단7단8단9단곱셈구구        2215\n",
      "         1단곱셈구구와0의곱        2215\n",
      "                곱셈표        2215\n",
      "          곱셈구구를활용하기        2215\n",
      "             길이알아보기        2215\n",
      "               길이의합        2215\n",
      "               길이의차        2215\n",
      "             길이어림하기        2215\n",
      "          하루의시간알아보기        2215\n",
      "             달력알아보기        2215\n",
      "\n",
      "클러스터 1 (6 개 노드):\n",
      "chapter_name  subject_id\n",
      "     두수의크기비교        2212\n",
      "       세수의계산        2214\n",
      "   받아올림이있는덧셈        2213\n",
      "   받아내림이있는뺄셈        2213\n",
      "       덧셈하기2        2213\n",
      "       뺄셈하기2        2213\n",
      "\n",
      "클러스터 2 (12 개 노드):\n",
      "  chapter_name  subject_id\n",
      "   2345를모으고가르기        2212\n",
      "   6789를모으고가르기        2212\n",
      "   몇십과몇십몇을알아보기        2212\n",
      "      백과몇백알아보기        2214\n",
      "      세자리수알아보기        2214\n",
      "         짝수와홀수        2213\n",
      "        몇시알아보기        2213\n",
      "10을이용하여모으기와가르기        2213\n",
      "      네자리수알아보기        2215\n",
      "         시각과시간        2215\n",
      "        표로나타내기        2215\n",
      "      그래프로나타내기        2215\n",
      "\n",
      "클러스터 3 (5 개 노드):\n",
      "chapter_name  subject_id\n",
      "       덧셈과뺄셈        2212\n",
      "    덧셈과뺄셈의관계        2214\n",
      "       의값구하기        2214\n",
      "       덧셈하기3        2213\n",
      "       뺄셈하기3        2213\n",
      "\n",
      "정리된 군집화 결과를 clustered_results.csv에 저장했습니다.\n",
      "\n",
      "Graph with embedding-based clustering saved to final_chapter_graph_clustered2.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 성취기준 흐름 기반 관계 생성\n",
    "flow_edges = []\n",
    "previous_id = None\n",
    "for _, row in data.iterrows():\n",
    "    current_id = row[\"f_mchapter_id\"]\n",
    "    if previous_id and previous_id != current_id:\n",
    "        flow_edges.append((previous_id, current_id))\n",
    "    previous_id = current_id\n",
    "\n",
    "# 유사도 기반 관계 생성 (가장 높은 유사도 하나만 유지)\n",
    "threshold = 0.95\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 군집별 색상 매핑\n",
    "cluster_colors = ['#FF4444', '#4444FF', '#44FF44', '#FFFF44']\n",
    "\n",
    "# K-means 군집화\n",
    "n_clusters = 4  # subject_id 개수와 동일하게 설정\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n",
    "cluster_labels = kmeans.fit_predict(bert_embeddings.cpu().numpy())\n",
    "\n",
    "# t-SNE로 차원 축소 (전체 데이터에 대해 한 번만 실행)\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=min(30, len(bert_embeddings) - 1),  # perplexity 값 조정\n",
    "    random_state=42,\n",
    "    n_iter=1000\n",
    ")\n",
    "embeddings_2d = tsne.fit_transform(bert_embeddings.cpu().numpy())\n",
    "\n",
    "# 노드 추가 (임베딩 기반 위치 정보 포함)\n",
    "for idx, (chapter_id, chapter_name) in enumerate(zip(data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"])):\n",
    "    # t-SNE 좌표를 기반으로 위치 설정\n",
    "    x, y = embeddings_2d[idx]\n",
    "    \n",
    "    # 스케일 조정 (더 넓은 공간에 분포하도록)\n",
    "    x = x * 10\n",
    "    y = y * 10\n",
    "    \n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        color=cluster_colors[cluster_labels[idx]],\n",
    "        size=30,\n",
    "        x=float(x),\n",
    "        y=float(y),\n",
    "        group=str(cluster_labels[idx])\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for source, target in final_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"#aaaaff\",\n",
    "        width=1,\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# PyVis로 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"groups\": {\n",
    "    \"0\": {\"color\": \"#FF4444\"},\n",
    "    \"1\": {\"color\": \"#4444FF\"},\n",
    "    \"2\": {\"color\": \"#44FF44\"},\n",
    "    \"3\": {\"color\": \"#FFFF44\"}\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# 군집화 결과 데이터프레임 생성\n",
    "cluster_info = pd.DataFrame({\n",
    "    'chapter_id': data['f_mchapter_id'],\n",
    "    'chapter_name': data['f_mchapter_nm'],\n",
    "    'subject_id': data['f_subject_id'],\n",
    "    'cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# 중복 제거 (chapter_name 기준으로 고유값만 유지)\n",
    "cluster_info_unique = cluster_info.drop_duplicates(subset=['chapter_name'])\n",
    "\n",
    "# 군집별 데이터 요약 출력\n",
    "print(\"\\n군집화 결과 분석:\")\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = cluster_info_unique[cluster_info_unique['cluster'] == cluster]\n",
    "    print(f\"\\n클러스터 {cluster} ({len(cluster_data)} 개 노드):\")\n",
    "    print(cluster_data[['chapter_name', 'subject_id']].to_string(index=False))\n",
    "\n",
    "# 저장할 경우 (옵션)\n",
    "output_file = \"clustered_results.csv\"\n",
    "cluster_info_unique.to_csv(output_file, index=False)\n",
    "print(f\"\\n정리된 군집화 결과를 {output_file}에 저장했습니다.\")\n",
    "\n",
    "# Save visualization\n",
    "output_file_html = \"final_chapter_graph_clustered2.html\"\n",
    "net.write_html(output_file_html)\n",
    "print(f\"\\nGraph with embedding-based clustering saved to {output_file_html}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 화살표 방향 : 시간의 흐름, 즉 학년 학기 순을 거스르지 않아야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER2\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "군집화 결과 분석:\n",
      "\n",
      "클러스터 0 (61 개 노드):\n",
      "       chapter_name  subject_id\n",
      "          12345알아보기        2212\n",
      "           6789알아보기        2212\n",
      "            9까지수의순서        2212\n",
      "1만큼더큰수와1만큼더작은수0알아보기        2212\n",
      "         여러가지모양찾아보기        2212\n",
      "         여러가지모양알아보기        2212\n",
      "        덧셈과뺄셈이야기만들기        2212\n",
      "                 덧셈        2212\n",
      "                 뺄셈        2212\n",
      "             길이비교하기        2212\n",
      "             무게비교하기        2212\n",
      "             넓이비교하기        2212\n",
      "         담을수있는양비교하기        2212\n",
      "             높이비교하기        2212\n",
      "              키비교하기        2212\n",
      "             10알아보기        2212\n",
      "             십몇알아보기        2212\n",
      "          50까지의수의순서        2212\n",
      "               뛰어세기        2214\n",
      "                 도형        2214\n",
      "               쌓기나무        2214\n",
      "        여러가지단위길이로재기        2214\n",
      "             자로길이재기        2214\n",
      "       길이를어림해보고재어보기        2214\n",
      "               분류하기        2214\n",
      "               묶어세기        2214\n",
      "            곱셈식알아보기        2214\n",
      "           곱셈식을활용하기        2214\n",
      "             몇십알아보기        2213\n",
      "         99까지의수알아보기        2213\n",
      "           수의순서알아보기        2213\n",
      "          두수의크기비교하기        2213\n",
      "       여러개의수의크기비교하기        2213\n",
      "           한자리세수의계산        2213\n",
      "             두수를더하기        2213\n",
      "           10이되는더하기        2213\n",
      "             10에서빼기        2213\n",
      "          10을만들어더하기        2213\n",
      "          여러가지모양만들기        2213\n",
      "          몇시30분알아보기        2213\n",
      "         몇시몇시30분의응용        2213\n",
      "               규칙찾기        2213\n",
      "             규칙만들기1        2213\n",
      "             규칙만들기2        2213\n",
      "              규칙찾기수        2213\n",
      "              덧셈하기1        2213\n",
      "              덧셈하기4        2213\n",
      "              뺄셈하기1        2213\n",
      "              뺄셈하기4        2213\n",
      "        1000과몇천알아보기        2215\n",
      "       2단3단5단6단곱셈구구        2215\n",
      "       4단7단8단9단곱셈구구        2215\n",
      "         1단곱셈구구와0의곱        2215\n",
      "                곱셈표        2215\n",
      "          곱셈구구를활용하기        2215\n",
      "             길이알아보기        2215\n",
      "               길이의합        2215\n",
      "               길이의차        2215\n",
      "             길이어림하기        2215\n",
      "          하루의시간알아보기        2215\n",
      "             달력알아보기        2215\n",
      "\n",
      "클러스터 1 (6 개 노드):\n",
      "chapter_name  subject_id\n",
      "     두수의크기비교        2212\n",
      "       세수의계산        2214\n",
      "   받아올림이있는덧셈        2213\n",
      "   받아내림이있는뺄셈        2213\n",
      "       덧셈하기2        2213\n",
      "       뺄셈하기2        2213\n",
      "\n",
      "클러스터 2 (12 개 노드):\n",
      "  chapter_name  subject_id\n",
      "   2345를모으고가르기        2212\n",
      "   6789를모으고가르기        2212\n",
      "   몇십과몇십몇을알아보기        2212\n",
      "      백과몇백알아보기        2214\n",
      "      세자리수알아보기        2214\n",
      "         짝수와홀수        2213\n",
      "        몇시알아보기        2213\n",
      "10을이용하여모으기와가르기        2213\n",
      "      네자리수알아보기        2215\n",
      "         시각과시간        2215\n",
      "        표로나타내기        2215\n",
      "      그래프로나타내기        2215\n",
      "\n",
      "클러스터 3 (5 개 노드):\n",
      "chapter_name  subject_id\n",
      "       덧셈과뺄셈        2212\n",
      "    덧셈과뺄셈의관계        2214\n",
      "       의값구하기        2214\n",
      "       덧셈하기3        2213\n",
      "       뺄셈하기3        2213\n",
      "\n",
      "정리된 군집화 결과를 clustered_results3.csv에 저장했습니다.\n",
      "\n",
      "Graph with embedding-based clustering saved to final_chapter_graph_clustered3.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 성취기준 흐름 기반 관계 생성 (f_subject_id를 고려한 방향 설정)\n",
    "flow_edges = []\n",
    "for i in range(len(data) - 1):\n",
    "    current_row = data.iloc[i]\n",
    "    next_row = data.iloc[i + 1]\n",
    "    \n",
    "    # f_subject_id 값 기준으로 방향 설정\n",
    "    if current_row[\"f_subject_id\"] < next_row[\"f_subject_id\"]:\n",
    "        flow_edges.append((current_row[\"f_mchapter_id\"], next_row[\"f_mchapter_id\"]))\n",
    "\n",
    "# 유사도 기반 관계 생성 (가장 높은 유사도 하나만 유지)\n",
    "threshold = 0.95\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 군집별 색상 매핑\n",
    "cluster_colors = ['#FF4444', '#4444FF', '#44FF44', '#FFFF44']\n",
    "\n",
    "# K-means 군집화\n",
    "n_clusters = 4  # subject_id 개수와 동일하게 설정\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n",
    "cluster_labels = kmeans.fit_predict(bert_embeddings.cpu().numpy())\n",
    "\n",
    "# t-SNE로 차원 축소 (전체 데이터에 대해 한 번만 실행)\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=min(30, len(bert_embeddings) - 1),  # perplexity 값 조정\n",
    "    random_state=42,\n",
    "    n_iter=1000\n",
    ")\n",
    "embeddings_2d = tsne.fit_transform(bert_embeddings.cpu().numpy())\n",
    "\n",
    "# 노드 추가 (임베딩 기반 위치 정보 포함)\n",
    "for idx, (chapter_id, chapter_name) in enumerate(zip(data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"])):\n",
    "    # t-SNE 좌표를 기반으로 위치 설정\n",
    "    x, y = embeddings_2d[idx]\n",
    "    \n",
    "    # 스케일 조정 (더 넓은 공간에 분포하도록)\n",
    "    x = x * 10\n",
    "    y = y * 10\n",
    "    \n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        color=cluster_colors[cluster_labels[idx]],\n",
    "        size=30,\n",
    "        x=float(x),\n",
    "        y=float(y),\n",
    "        group=str(cluster_labels[idx])\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for source, target in final_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"#aaaaff\",\n",
    "        width=1,\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# PyVis로 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"groups\": {\n",
    "    \"0\": {\"color\": \"#FF4444\"},\n",
    "    \"1\": {\"color\": \"#4444FF\"},\n",
    "    \"2\": {\"color\": \"#44FF44\"},\n",
    "    \"3\": {\"color\": \"#FFFF44\"}\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# 군집화 결과 데이터프레임 생성\n",
    "cluster_info = pd.DataFrame({\n",
    "    'chapter_id': data['f_mchapter_id'],\n",
    "    'chapter_name': data['f_mchapter_nm'],\n",
    "    'subject_id': data['f_subject_id'],\n",
    "    'cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# 중복 제거 (chapter_name 기준으로 고유값만 유지)\n",
    "cluster_info_unique = cluster_info.drop_duplicates(subset=['chapter_name'])\n",
    "\n",
    "# 군집별 데이터 요약 출력\n",
    "print(\"\\n군집화 결과 분석:\")\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = cluster_info_unique[cluster_info_unique['cluster'] == cluster]\n",
    "    print(f\"\\n클러스터 {cluster} ({len(cluster_data)} 개 노드):\")\n",
    "    print(cluster_data[['chapter_name', 'subject_id']].to_string(index=False))\n",
    "\n",
    "# 저장할 경우 (옵션)\n",
    "output_file = \"clustered_results3.csv\"\n",
    "cluster_info_unique.to_csv(output_file, index=False)\n",
    "print(f\"\\n정리된 군집화 결과를 {output_file}에 저장했습니다.\")\n",
    "\n",
    "# Save visualization\n",
    "output_file_html = \"final_chapter_graph_clustered3.html\"\n",
    "net.write_html(output_file_html)\n",
    "print(f\"\\nGraph with embedding-based clustering saved to {output_file_html}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 화살표 방향(역순흐름X) & 2022년 개정 수학 교육부 성취기준 4개 영역(수와연산,변화와관계,도형과측정,자료와가능성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph with embedding-based clustering saved to final_chapter_graph_clustered4.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new - 복사본.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# 군집화 및 학년 학기 색상 매핑\n",
    "area_colors = {\n",
    "    \"수와 연산\": \"#FFCCCC\",\n",
    "    \"변화와 관계\": \"#CCCCFF\",\n",
    "    \"도형과 측정\": \"#CCFFCC\",\n",
    "    \"자료와 가능성\": \"#FFFFCC\",\n",
    "    \"기타\": \"#CCCCCC\"\n",
    "}\n",
    "subject_colors = {\n",
    "    2212: \"#FF0000\",  # 1학년 1학기\n",
    "    2213: \"#0000FF\",  # 1학년 2학기\n",
    "    2214: \"#00FF00\",  # 2학년 1학기\n",
    "    2215: \"#FFFF00\"   # 2학년 2학기\n",
    "}\n",
    "\n",
    "def get_area_by_code(code):\n",
    "    if code.startswith(\"2수01\"):\n",
    "        return \"수와 연산\"\n",
    "    elif code.startswith(\"2수02\"):\n",
    "        return \"변화와 관계\"\n",
    "    elif code.startswith(\"2수03\"):\n",
    "        return \"도형과 측정\"\n",
    "    elif code.startswith(\"2수04\"):\n",
    "        return \"자료와 가능성\"\n",
    "    else:\n",
    "        return \"기타\"\n",
    "\n",
    "data[\"area\"] = data[\"성취기준코드\"].apply(get_area_by_code)\n",
    "data[\"color\"] = data[\"area\"].map(area_colors)\n",
    "data[\"border_color\"] = data[\"f_subject_id\"].map(subject_colors)\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 흐름 기반 엣지 생성\n",
    "flow_edges = []\n",
    "for i in range(len(data) - 1):\n",
    "    current_row = data.iloc[i]\n",
    "    next_row = data.iloc[i + 1]\n",
    "    if (current_row[\"f_subject_id\"] < next_row[\"f_subject_id\"] or\n",
    "        (current_row[\"f_subject_id\"] == next_row[\"f_subject_id\"] and\n",
    "         current_row[\"성취기준코드\"] < next_row[\"성취기준코드\"])):\n",
    "        flow_edges.append((current_row[\"f_mchapter_id\"], next_row[\"f_mchapter_id\"]))\n",
    "\n",
    "# 유사도 기반 관계 생성\n",
    "threshold = 0.85\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "nodes_json = []\n",
    "for idx, (chapter_id, chapter_name, color, border_color) in enumerate(zip(\n",
    "    data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"], data[\"color\"], data[\"border_color\"]\n",
    ")):\n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        color={\n",
    "            \"background\": color,\n",
    "            \"border\": border_color\n",
    "        },\n",
    "        size=30,\n",
    "        borderWidth=2\n",
    "    )\n",
    "    nodes_json.append({\n",
    "        \"id\": chapter_id,\n",
    "        \"name\": chapter_name,\n",
    "        \"area\": data.loc[idx, \"area\"],\n",
    "        \"subject_id\": data.loc[idx, \"f_subject_id\"],\n",
    "        \"color\": color,\n",
    "        \"border_color\": border_color\n",
    "    })\n",
    "\n",
    "# 엣지 추가\n",
    "edges_json = []\n",
    "for source, target in final_edges:\n",
    "    if str(source) in graph.nodes and str(target) in graph.nodes and source != target:\n",
    "        graph.add_edge(\n",
    "            str(source), str(target),\n",
    "            color=\"#aaaaff\",\n",
    "            width=1,\n",
    "            title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "        )\n",
    "        edges_json.append({\n",
    "            \"source\": source,\n",
    "            \"target\": target\n",
    "        })\n",
    "\n",
    "# PyVis 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# 그래프 저장\n",
    "output_file_html = \"final_chapter_graph_clustered4.html\"\n",
    "net.write_html(output_file_html)\n",
    "print(f\"\\nGraph with embedding-based clustering saved to {output_file_html}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER2\\anaconda3\\envs\\myenv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph with legend and clustering saved to final_chapter_graph_with_legend.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# 군집화 및 학년 학기 색상 매핑\n",
    "area_colors = {\n",
    "    \"수와 연산\": \"#FFCCCC\",\n",
    "    \"변화와 관계\": \"#CCCCFF\",\n",
    "    \"도형과 측정\": \"#CCFFCC\",\n",
    "    \"자료와 가능성\": \"#FFFFCC\",\n",
    "    \"기타\": \"#CCCCCC\"\n",
    "}\n",
    "subject_colors = {\n",
    "    2212: \"#FF0000\",  # 1학년 1학기\n",
    "    2213: \"#0000FF\",  # 1학년 2학기\n",
    "    2214: \"#00FF00\",  # 2학년 1학기\n",
    "    2215: \"#FFFF00\"   # 2학년 2학기\n",
    "}\n",
    "\n",
    "def get_area_by_code(code):\n",
    "    if code.startswith(\"2수01\"):\n",
    "        return \"수와 연산\"\n",
    "    elif code.startswith(\"2수02\"):\n",
    "        return \"변화와 관계\"\n",
    "    elif code.startswith(\"2수03\"):\n",
    "        return \"도형과 측정\"\n",
    "    elif code.startswith(\"2수04\"):\n",
    "        return \"자료와 가능성\"\n",
    "    else:\n",
    "        return \"기타\"\n",
    "\n",
    "data[\"area\"] = data[\"성취기준코드\"].apply(get_area_by_code)\n",
    "data[\"color\"] = data[\"area\"].map(area_colors)\n",
    "data[\"border_color\"] = data[\"f_subject_id\"].map(subject_colors)\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 흐름 기반 엣지 생성\n",
    "flow_edges = []\n",
    "for i in range(len(data) - 1):\n",
    "    current_row = data.iloc[i]\n",
    "    next_row = data.iloc[i + 1]\n",
    "    if (current_row[\"f_subject_id\"] < next_row[\"f_subject_id\"] or\n",
    "        (current_row[\"f_subject_id\"] == next_row[\"f_subject_id\"] and\n",
    "         current_row[\"성취기준코드\"] < next_row[\"성취기준코드\"])): \n",
    "        flow_edges.append((current_row[\"f_mchapter_id\"], next_row[\"f_mchapter_id\"]))\n",
    "\n",
    "# 유사도 기반 관계 생성\n",
    "threshold = 0.85\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "nodes_json = []\n",
    "for idx, (chapter_id, chapter_name, color, border_color) in enumerate(zip(\n",
    "    data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"], data[\"color\"], data[\"border_color\"]\n",
    ")):\n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        color={\n",
    "            \"background\": color,\n",
    "            \"border\": border_color\n",
    "        },\n",
    "        size=30,\n",
    "        borderWidth=2\n",
    "    )\n",
    "    nodes_json.append({\n",
    "        \"id\": chapter_id,\n",
    "        \"name\": chapter_name,\n",
    "        \"area\": data.loc[idx, \"area\"],\n",
    "        \"subject_id\": data.loc[idx, \"f_subject_id\"],\n",
    "        \"color\": color,\n",
    "        \"border_color\": border_color\n",
    "    })\n",
    "\n",
    "# 엣지 추가\n",
    "edges_json = []\n",
    "for source, target in flow_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"#aaaaaa\",  # 흐름 기반 엣지 색상\n",
    "        width=1,\n",
    "        title=\"선후행 관계\"\n",
    "    )\n",
    "    edges_json.append({\n",
    "        \"source\": source,\n",
    "        \"target\": target\n",
    "    })\n",
    "\n",
    "for source, target in similarity_edges:\n",
    "    graph.add_edge(\n",
    "        str(source), str(target),\n",
    "        color=\"#ffa500\",  # 유사도 기반 엣지 색상\n",
    "        width=2,\n",
    "        title=\"유사도 기반 연결\"\n",
    "    )\n",
    "    edges_json.append({\n",
    "        \"source\": source,\n",
    "        \"target\": target\n",
    "    })\n",
    "\n",
    "# PyVis 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 범례 추가\n",
    "legend_html = '''\n",
    "<div style=\"position:absolute;top:10px;left:10px;background-color:white;padding:10px;border-radius:5px;box-shadow:0 0 10px rgba(0,0,0,0.5);z-index:1000;font-size:14px;\">\n",
    "  <strong>범례</strong>\n",
    "  <ul>\n",
    "    <li style=\"color:#FFCCCC;\">수와 연산</li>\n",
    "    <li style=\"color:#CCCCFF;\">변화와 관계</li>\n",
    "    <li style=\"color:#CCFFCC;\">도형과 측정</li>\n",
    "    <li style=\"color:#FFFFCC;\">자료와 가능성</li>\n",
    "  </ul>\n",
    "  <ul>\n",
    "    <li style=\"color:#FF0000;\">1학년 1학기</li>\n",
    "    <li style=\"color:#0000FF;\">1학년 2학기</li>\n",
    "    <li style=\"color:#00FF00;\">2학년 1학기</li>\n",
    "    <li style=\"color:#FFFF00;\">2학년 2학기</li>\n",
    "  </ul>\n",
    "</div>\n",
    "'''\n",
    "net.html = legend_html + net.html\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# 그래프 저장\n",
    "output_file_html = \"final_chapter_graph_with_legend.html\"\n",
    "net.write_html(output_file_html)\n",
    "print(f\"\\nGraph with legend and clustering saved to {output_file_html}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학년학기랑 영역구분 색상 없애고, json파일 저장\n",
    "### json 파일에 소단원, 토픽단원까지 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph data saved to graph_data1.json\n",
      "\n",
      "Graph with embedding-based clustering saved to final_chapter_graph_clustered5.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "file_path = \"merged_final_data_new.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"f_mchapter_id\", \"f_mchapter_nm\", \"f_subject_id\", \"성취기준코드\", \"성취기준 내용\",\n",
    "    \"핵심키워드_v2\", \"성취수준 A\", \"성취수준 B\", \"성취수준 C\", \"f_schapter_id\", \"f_schapter_nm\", \"f_tchapter_id\", \"f_tchapter_nm\"\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"Required column '{col}' is missing from the data\")\n",
    "\n",
    "# Preprocess data\n",
    "data[\"f_mchapter_nm\"] = data[\"f_mchapter_nm\"].str.strip().str.replace(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", regex=True)\n",
    "data[\"bert_text\"] = (\n",
    "    data[\"성취기준 내용\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 A\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 B\"].fillna(\"\") + \" \" +\n",
    "    data[\"성취수준 C\"].fillna(\"\")\n",
    ")\n",
    "data[\"tfidf_text\"] = data[\"핵심키워드_v2\"].fillna(\"\")\n",
    "\n",
    "# Sentence-BERT similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bert_embeddings = model.encode(data[\"bert_text\"].tolist(), convert_to_tensor=True)\n",
    "bert_sim = cosine_similarity(bert_embeddings.cpu(), bert_embeddings.cpu())\n",
    "\n",
    "# TF-IDF similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"tfidf_text\"])\n",
    "tfidf_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Combine similarities\n",
    "final_sim = 0.8 * bert_sim + 0.2 * tfidf_sim\n",
    "\n",
    "# 흐름 기반 엣지 생성\n",
    "flow_edges = []\n",
    "for i in range(len(data) - 1):\n",
    "    current_row = data.iloc[i]\n",
    "    next_row = data.iloc[i + 1]\n",
    "    if (current_row[\"f_subject_id\"] < next_row[\"f_subject_id\"] or\n",
    "        (current_row[\"f_subject_id\"] == next_row[\"f_subject_id\"] and\n",
    "         current_row[\"성취기준코드\"] < next_row[\"성취기준코드\"])):\n",
    "        flow_edges.append((current_row[\"f_mchapter_id\"], next_row[\"f_mchapter_id\"]))\n",
    "\n",
    "# 유사도 기반 관계 생성\n",
    "threshold = 0.85\n",
    "similarity_edges = []\n",
    "node_max_connections = {}\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if final_sim[i, j] >= threshold:\n",
    "            source_id = data.iloc[i][\"f_mchapter_id\"]\n",
    "            target_id = data.iloc[j][\"f_mchapter_id\"]\n",
    "            if source_id != target_id:\n",
    "                if source_id not in node_max_connections or node_max_connections[source_id][1] < final_sim[i, j]:\n",
    "                    node_max_connections[source_id] = (target_id, final_sim[i, j])\n",
    "\n",
    "for source_id, (target_id, weight) in node_max_connections.items():\n",
    "    similarity_edges.append((source_id, target_id))\n",
    "\n",
    "# Combine edges\n",
    "final_edges = list(set(flow_edges + similarity_edges))\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "nodes_json = []\n",
    "for idx, (chapter_id, chapter_name, subject_id, code, schapter_id, schapter_name, tchapter_id, tchapter_name) in enumerate(zip(\n",
    "    data[\"f_mchapter_id\"], data[\"f_mchapter_nm\"], data[\"f_subject_id\"], data[\"성취기준코드\"],\n",
    "    data[\"f_schapter_id\"], data[\"f_schapter_nm\"], data[\"f_tchapter_id\"], data[\"f_tchapter_nm\"]\n",
    ")):\n",
    "    graph.add_node(\n",
    "        str(chapter_id),\n",
    "        label=chapter_name,\n",
    "        size=30,\n",
    "        borderWidth=2\n",
    "    )\n",
    "    nodes_json.append({\n",
    "        \"id\": chapter_id,\n",
    "        \"name\": chapter_name,\n",
    "        \"f_subject_id\": subject_id,\n",
    "        \"성취기준코드\": code,\n",
    "        \"f_schapter_id\": schapter_id,\n",
    "        \"f_schapter_name\": schapter_name,\n",
    "        \"f_tchapter_id\": tchapter_id,\n",
    "        \"f_tchapter_name\": tchapter_name\n",
    "    })\n",
    "\n",
    "# 엣지 추가\n",
    "edges_json = []\n",
    "for source, target in final_edges:\n",
    "    if str(source) in graph.nodes and str(target) in graph.nodes and source != target:\n",
    "        graph.add_edge(\n",
    "            str(source), str(target),\n",
    "            color=\"#aaaaff\",\n",
    "            width=1,\n",
    "            title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "        )\n",
    "        edges_json.append({\n",
    "            \"source\": source,\n",
    "            \"target\": target\n",
    "        })\n",
    "\n",
    "# PyVis 시각화\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "net.from_nx(graph)\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# 그래프 저장\n",
    "output_file_html = \"final_chapter_graph_clustered5.html\"\n",
    "net.write_html(output_file_html)\n",
    "\n",
    "# JSON 데이터 생성\n",
    "graph_json = {\n",
    "    \"nodes\": nodes_json,\n",
    "    \"edges\": edges_json\n",
    "}\n",
    "\n",
    "# Ensure all non-serializable values are converted to serializable types\n",
    "def convert_values_to_serializable(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return [convert_values_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_values_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32)):\n",
    "        return float(obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "graph_json = convert_values_to_serializable(graph_json)\n",
    "\n",
    "# JSON 파일로 저장\n",
    "output_json_file = \"graph_data1.json\"\n",
    "with open(output_json_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(graph_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nGraph data saved to {output_json_file}\")\n",
    "print(f\"\\nGraph with embedding-based clustering saved to {output_file_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph reconstructed and saved to reconstructed_graph.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "# JSON 파일 로드\n",
    "input_json_file = \"graph_data1.json\"  # 생성된 JSON 파일 경로\n",
    "with open(input_json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    graph_data = json.load(f)\n",
    "\n",
    "# PyVis 네트워크 생성\n",
    "net = Network(height=\"100vh\", width=\"100vw\", directed=True, bgcolor=\"#ffffff\", font_color=\"#000000\")\n",
    "\n",
    "# 노드 추가\n",
    "for node in graph_data[\"nodes\"]:\n",
    "    net.add_node(\n",
    "        str(node[\"id\"]),\n",
    "        label=node[\"name\"],\n",
    "        size=30,\n",
    "        borderWidth=2\n",
    "    )\n",
    "\n",
    "# 엣지 추가\n",
    "for edge in graph_data[\"edges\"]:\n",
    "    net.add_edge(\n",
    "        str(edge[\"source\"]),\n",
    "        str(edge[\"target\"]),\n",
    "        color=\"#aaaaff\",\n",
    "        width=1,\n",
    "        title=\"선후행 관계 및 유사도 기반 연결\"\n",
    "    )\n",
    "\n",
    "# 물리적 레이아웃 설정\n",
    "net.set_options('''\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.005,\n",
    "      \"springLength\": 100,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.4,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\",\n",
    "    \"stabilization\": {\n",
    "      \"enabled\": true,\n",
    "      \"iterations\": 2000,\n",
    "      \"updateInterval\": 25\n",
    "    }\n",
    "  },\n",
    "  \"nodes\": {\n",
    "    \"shape\": \"dot\",\n",
    "    \"size\": 25,\n",
    "    \"font\": {\n",
    "      \"size\": 14\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"arrows\": {\n",
    "      \"to\": {\n",
    "        \"enabled\": true,\n",
    "        \"scaleFactor\": 0.5\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# HTML 파일로 저장\n",
    "output_html_file = \"reconstructed_graph.html\"\n",
    "net.write_html(output_html_file)\n",
    "print(f\"\\nGraph reconstructed and saved to {output_html_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
